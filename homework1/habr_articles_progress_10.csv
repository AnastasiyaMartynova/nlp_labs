title,author,publish_date,hubs,text,views,comments,rating,reading_time,url,text_length,word_count,hubs_count
"Один в поле не воин: как собрать команду для мероприятия, чтобы всё прошло гладко (и вы не сошли с ума)",kseniaevent,2025-11-13T06:04:31.000Z,"['Developer Relations *', 'Конференции', 'Управление персоналом *', 'Управление проектами *']","kseniaevent 5 часов назадОдин в поле не воин: как собрать команду для мероприятия, чтобы всё прошло гладко (и вы не сошли с ума)Уровень сложностиПростойВремя на прочтение8 минКоличество просмотров100Developer Relations * КонференцииУправление персоналом * Управление проектами * ТуториалПривет! Продолжаем говорить про организацию мероприятий для непрофессиональных ивентеров. HR, ассистенты, руководители проектов, маркетологи, пиарщики и все те, на чью долю выпало в нагрузку к основным рабочим обязанностям сделать мероприятие, эта статья для вас.Мы уже обсудили с чего начать подготовку к мероприятию, его упаковку, CJM участников, выбор площадки, организацию питания, как собрать программу, фото-/видеосъемку, организацию трансляции и спонсорские интеграции. Пришло время поговорить про команду. Как мы уже говорили ранее, в случае мероприятия один в поле - не воин. Это не только довольно тяжело физически и морально, но и опасно, так как если организатор делает все сам, то он представляет из себя страшный bus-фактор и если с ним что-то случится, то мероприятие может сорваться. Поэтому в этом разделе мы рассмотрим основные роли, которые могут быть в команде. В зависимости от масштаба мероприятия некоторые из этих ролей могут не пригождаться. Но я верю в то, что данный список поможет вам охватить контролем все зоны мероприятия и не взять на себя лишнего. Ключевые роли и их функцииКаждый член команды играет важную роль, и от их профессионализма, ответственности и способности работать вместе зависит общий успех. При формировании команды важно учитывать компетенции участников, четко распределять обязанности и зоны ответственности, корректно и понятно ставить задачи и контролировать их выполнение.Ключевые роли и их функцииМенеджер проекта - руководитель команды и основной координатор всех процессов. В его обязанности входит:Планирование всех этапов мероприятия.Контроль сроков, бюджета и ресурсов.Управление рисками и решение непредвиденных ситуаций.Он несет ответственность за все мероприятие в целом.Менеджер по продвижению - отвечает за привлечение участников и создание информационного поля вокруг мероприятия. На этой роли могут быть маркетологи, smm-менеджеры, контент-менеджеры и даже менеджеры по внутренним коммуникациям в зависимости от специфики вашего мероприятия и маркетинговой стратегииОсновные задачи:Разработка стратегии продвижения.Подготовка и размещение рекламных материалов.Работа с соцсетями и аналитикой.Дизайнер - тот человек, который сделает вам красиво. Задачи дизайнера минимально включают:Создание визуальной айдентики мероприятияРазработку логотипов, баннеров, презентаций и иных брендированных материалов.Подготовку макетов для печати.Веб-разработчик или команда - обеспечивают создание и техническую поддержку сайта мероприятия. Копирайтер - создает все тексты, которые будут использованы в рамках мероприятия, за исключением сценария разве что, хотя и там копирайтер может приложить свою руку к отдельным частям. Может также быть представлен в роли smm-менеджера. Задачи:Написание пресс-релизов, постов, анонсов.Подготовка текстов для ведущих и спикеров.Вычитка текстов от СМИРежиссер-сценарист - это может быть как один человек, который совмещает в себе обе роли, так и отдельные люди. Суть от этого не меняется, задача сформировать и реализовать программу. Обычно речь все же идет про шоу-программу. Кстати, режиссер мероприятия и режиссер трансляции - это точно 2 разных человека, если у вас гибридное мероприятие.Задачи: Составление сценария.Координация тайминга шоу. Постановка номеров.Организация репетиций.Программный директор и/или комитет - тоже работают над программой, но уже деловых событий и конференций, там, где встречаются доклады. Задачи: Наполнение программы в соответствии с тематикой мероприятия.Выбор подходящих докладов и их доработка.Репетиции с выступающими. Иногда они также занимаются модерацией и контролем за проведением сессий и выступлений.Юрист - проверяет все договоры, подписываемые с подрядчиками, партнерами и спонсорами, консультирует по вопросам соблюдения прав гостей (например, согласие на обработку персональных данных или съемку), разрабатывает договоры с сотрудниками и временным персоналом.Бухгалтер - отвечает за все финансовые операции: расчеты с подрядчиками, оплата услуг и закупок, организует прием оплаты от участников, если мероприятие платное. Иногда, если планируется продажа чего-либо в день мероприятия, то помогает с организацией приема оплаты на площадке. Банкетный менеджер - в некоторых случаях вам придется нанять и его, если площадка сама не справляется (см. подробнее в главе «Питание»). Отвечает за весь сервис связанные с питанием гостей и персонала, помогает составить меню, следит за его реализацией, контролирует выносы и объемы потребления. Хорошо бы, чтобы он имел доступ на кухню на случай кризисных ситуаций, а для этого нужна мед.книжка и предварительное согласование с кухней.Персонал на площадке в день мероприятияДля оперативной работы на площадке важно заранее определить и заказать или найти среди сотрудников необходимый персонал. Ниже очень важные люди, про которых очень часто забываютПерсонал на площадке в день мероприятияРегистраторы - встречают гостей, выдают бейджи и материалы. Мы говорили о них в блоке про организацию площадки и работу с гостямиХостесс - помогают с навигацией и отвечают на вопросы участников. Обычно приглашаются на более статичные мероприятия. На мероприятиях попроще могут быть заменены на волонтеров.Монтажно-демонтажная группа (АХО) - отвечает за установку оборудования и декораций.Охрана - обеспечивает безопасность гостей и защищает имущество. Подробнее в блоке про охрануГардеробщики - заботятся о хранении верхней одежды гостей.Клинеры - поддерживают чистоту и порядок на протяжении мероприятия.Информационная стойка - предоставляет информацию и оперативно решает вопросы. Расположена на площадке мероприятияКонсьерж - помогает гостям с заказом такси, билетов, навигацией по городу. Обычно встречается на ВИП-мероприятихКолл-центр или саппорт - отвечают на вопросы гостей в чате / боте / по телефонуВолонтеры — незаменимые помощники, особенно на больших мероприятиях.  Их основные задачи встреча гостей и помощь с навигацией, помощь в функциональных зонах (нетворкинг, фуд-корт, мастер-классы), быстрое реагирование на запросы организаторов (дай-подай-принеси). Супервайзер волонтеров - обучает и координирует работу команды волонтеров, а также контролирует их в день мероприятия, решает возникающие проблемы и следит за соблюдением расписания.Хелперы - диапазон их задач довольно велик, я для себя делю их на технические - помощь с застройкой, перетаскиванием и прочими физическими работами, которые не связаны с взаимодействием с гостями, и административные - это своего рода платные волонтеры, возможно, несколько более опытные, которые представляют собой запасной человеческий ресурс. Ими можно усилить регистрацию, потом перекинуть на навигацию, при необходимости попросить встретить спикера и т.д.Курьеры - их тоже часто забывают заложить в бюджет, поэтому напомню об этой статье тоже - доставляют материалы, оборудование и еду. Если в процессе организации вы можете пользоваться приложениями, то в день мероприятия, если оно напряженное и вы понимаете, что вам нужно оказывать сервис превосходящий ожидания, то хорошо бы иметь дежурного курьера во время всего мероприятия. Вообще это просто может быть водитель с машиной, который сможет съездить по вашему поручению. Сотрудники для функциональных зон - координируют работу зон нетворкинга, фотозон, интерактивных площадок, залов и проч. Они следят за выполнением запланированных активностей и решают возникающие вопросы. В зависимости от формата мероприятия важно предусмотреть персонал для контроля всех важных зон. На небольших мероприятиях допускается совмещение. Подбор временного персонала и его обучениеЧасто для проведения мероприятий нанимается временный персонал, это нормальная практика. Его правильная подготовка и управление являются залогом успеха и хорошего клиентского опыта ваших гостей. Рассмотрим основные этапы подготовкиПодборСейчас есть специализированные агентства, которые предоставляют временные персонал для мероприятия. Обычно это самый безопасный и надежный способ поиска. Выбирайте активных, коммуникабельных и ответственных людей. Просите отзывы и опыт работы на других мероприятиях. Проводите интервью с теми, кто будет много коммуницировать с гостями не по стандартному протоколу.Согласование условий работыЗаранее согласуйте график работы и обязанности временного персонала.Согласуйте оплату и форму одежды персонала в день мероприятия. Не стесняйтесь запрашивать фото, если персонал будет в своей одежде. Если вы предполагаете бронированную одежду, то соберите размеры и закажите ее. Мой совет, берите что-то в стиле one size, так как часть персонала может «отвалиться» в процессе подготовки и будет заменена другими людьми.Обеспечьте удобное место для отдыха между сменами, а также питание в случае длительных смен.Предусмотрите технические перерывы и человека, который будет на замене на время перерываНазначьте супервайзера для контроля временного персонала. Если у вас много временного персонала, то берите супервайзеров для каждой категории. Супервайзер должен быть связующим звеном между персоналом и организаторами, обеспечивать своевременную ротацию людей, чтобы избежать их перегрузки и быстро реагировать на вопросы и проблемы.Обучение Проведите вводный инструктаж на площадке за несколько дней до мероприятия, если есть такая возможность. Хотя бы покажите заранее площадку супервайзерам, чтобы в день мероприятия они смогли сами расставить подконтрольный им персонал и проинструктировать. Перед инструктажем на площадке рекомендую выслать письменную инструкцию со всеми правилами, чтобы во время очной встречи ответить на вопросы. Также эта инструкция будет шпаргалкой для вас, чтобы ничего не забыть. Разъясняйте обязанности, моделируйте ситуации и смотрите за реакцией. Обучите заранее работе с оборудованием и навигацией.Распределение зон ответственности Назначайте задачи в зависимости от интересов и компетенций персонала. Особенно это касается волонтеров и хелперов, которые в целом многофункциональны, но обычно имеют сильные стороны и предпочтения.Контроль в день мероприятияВ процессе мероприятия вы должны контролировать работу временного персонала. Если у вас есть супервайзер, то это происходит через него. Ег задача присылать вам периодически фото того, что персонал в нужном количестве находится в своем месте и выполняет обязанности. Также супервайзер следит за общением с гостями, если оно предусмотрено и корректирует его при необходимости. Благодарность после мероприятияНе забудьте после мероприятия поблагодарить весь персонал. Если не успеваете лично, то хотя бы передайте благодарности через супервайзера. При необходимости будьте готовы написать благодарственные письма. Если у вас работают волонтеры на безвозмездной основе, то подарите им фирменный мерч или иным способом порадуйте ребят. Кстати, у меня было несколько кейсов, когда встречались настолько хорошие волонтеры, что мы обменивались контактами и продолжали работать на других мероприятиях уже на платных условиях. Некоторые даже работали в штате компании какое-то время. Так что, не упускайте хорошие кадры.  Организация работы внутренней командыДопустим, вы добились того, что ваши коллеги будут вам помогать в процессе организации мероприятия и у них даже выделены время и ресурс на это. Для эффективной работы команды необходимо выстроить четкую систему внутренней коммуникации. Минимальный чек-листНазначьте ответственных за различные направления, чтобы минимизировать хаос в коммуникациях и понимать, с кого спрашивать результат.Создайте общий чат в мессенджере для оперативного решения вопросов. Возможно, будет даже несколько чатов по разным направлениям мероприятия. Проводите регулярные встречи для обсуждения задач и решения проблем. Будьте на связи и выстраивайте открытую коммуникацию, чтобы сотрудники не боялись задавать вам уточняющие вопросы и просить помощи в решении проблем. Ничего не замалчивайте.Организуйте перерывы для отдыха и питания, особенно во время интенсивных дней подготовки и самого мероприятия.Контролируйте работу в день мероприятия и просите регулярно (периодичность установите сами) присылать вам уведомления, все ли идет хорошо в их зоне ответственностиПредусмотрите бонусы или подарки по итогам мероприятия.Мой принцип в коммуникации с командой ивента: демократия в процессе подготовки и деспотизм на площадке. В процессе подготовки мы всегда могли обсудить разные варианты решения задач и я всегда рада выслушать мнение команды, но на площадке на демократию часто не остается времени, особенно в ситуации форс-мажора, я ответственна за весь процесс и поэтому придется принимать мои решения, даже если они кажутся неверными.  Ксения КазаковаHR-проекты / Employer Brand / DevRelТеги:мероприятияконференцииуправление людьмиуправление проектамиуправление командойХабы:Developer RelationsКонференцииУправление персоналомУправление проектами",100,0,0,8 мин,https://habr.com/ru/articles/964316/,13025,1685,4
Очереди сообщений в Postgres Pro: отказ от внешних брокеров ради транзакционной надёжности,slonik_pg,2025-11-12T15:32:34.000Z,"['Блог компании Postgres Professional', 'SQL *', 'PostgreSQL *', 'Базы данных *', 'Серверное администрирование *']","slonik_pg 19 часов назадОчереди сообщений в Postgres Pro: отказ от внешних брокеров ради транзакционной надёжностиУровень сложностиПростойВремя на прочтение7 минКоличество просмотров3.3KБлог компании Postgres ProfessionalSQL * PostgreSQL * Базы данных * Серверное администрирование * ОбзорВ эпоху распределённых систем, где каждая компонента должна быть не только эффективной, но и предсказуемой, вопрос надёжности обмена данными становится критическим. Представьте: пользователь нажимает кнопку «Сгенерировать отчёт», и в этот момент должны синхронизироваться десятки процессов — от создания документа до его отправки по email. Но что если почтовый сервер временно недоступен? Или обработчик задач падает, не завершив операцию? Именно здесь на сцену выходят очередь сообщений — механизм, который превращает хаотичные запросы в управляемый поток, гарантируя, что ни одна задача не потеряется в пути.История создания расширения встроенных очередей в PostgreSQL началась с простой боли: внешние брокеры вроде RabbitMQ или Kafka, хотя и мощные, добавляли слои сложности. Управление ими требует выделенных ресурсов: отдельные серверы, настройка кластеров, мониторинг доступности. В enterprise-среде, где системы развертываются тысячами экземпляров, каждый новый компонент увеличивает риски и административную нагрузку.Зачем подключать отдельный брокер, если очередь уже встроена в базу данных и работает «из коробки»? Это не только экономит время, но и исключает проблемы согласованности: если транзакция откатывается, сообщение автоматически возвращается в очередь для повторной попытки, без единой строчки дополнительного кода.Два подхода к очередям: Log-based и AMQP/JMSВ мире распределенных систем сформировались два подхода к обработке сообщений:Log-based-очереди (например, Kafka). Работают как непрерывный журнал событий. Данные записываются строго последовательно, и потребители читают их в том же порядке. Это идеально для синхронизации данных между микросервисами или репликации баз данных. Однако их сила — в линейности — становится слабостью, когда нужна гибкость: выборка сообщений по приоритету или фильтрам здесь невозможна.AMQP/JMS-брокеры (например, RabbitMQ). Позволяют не просто передавать сообщения, но и управлять их жизненным циклом: устанавливать приоритеты, фильтровать по условиям, обрабатывать ошибки. Такие очереди позволяют имитировать асинхронное RPC, где задача может быть повторена при сбоях. Но их главная слабость — фундаментальная проблема, общая для любого внешнего брокера, включая Kafka: невозможно гарантировать транзакционную целостность с базой данных.Проблемы внешних брокеров: транзакционность и сложностьИспользование внешних брокеров, таких как Kafka или RabbitMQ, в enterprise-средах часто сопряжено со скрытыми сложностями:Рассогласование данных. Представьте сценарий: приложение отправляет сообщение в RabbitMQ и начинает транзакцию в базе данных. Сообщение уже ушло в брокер, но в момент коммита транзакции в БД происходит сбой. Результат — рассогласование: задача будет обработана, но данные для неё не сохранены. Попытки гарантировать атомарность через двухфазный коммит (2PC) усложняют архитектуру, требуя дополнительного координатора транзакций, а также заметно снижают производительность.Административная нагрузка. Внешние брокеры требуют отдельной инсталляции, настройки, мониторинга и резервного копирования. Это создаёт дополнительные точки отказа (например, сетевые сбои между сервером приложений и брокером) и усложняет поддержку, особенно если за СУБД и брокер отвечают разные команды.Postgres Pro Enterprise Queues: транзакционность и автоматизация с pgpro_queueНовое расширение pgpro_queue — это ответ на «боль» разработчиков, уставших бороться с рассогласованием данных. Интеграция очередей непосредственно в СУБД устраняет необходимость во внешних компонентах. Сообщения хранятся в обычных таблицах, реплицируются через стандартные механизмы PostgreSQL и участвуют в тех же транзакциях, что и бизнес-логика приложения.Установка и настройкаИнтеграция pgpro_queue начинается с простых шагов, знакомых любому DBA:Добавление в shared_preload_libraries. В файле postgresql.conf необходимо добавить расширение в список предварительно загружаемых библиотек:shared_preload_libraries = 'pgpro_queue'Создание расширения. В нужной базе данных выполняется команда:CREATE EXTENSION pgpro_queue;Инициализация. Для хранения служебных объектов (таблиц метаданных, очередей) создаётся отдельная схема pgpro_queue_data. Это делается с помощью функции:SELECT queue_initialize();Такое разделение обеспечивает корректную работу pg_dump и репликации.Ключевые возможности и их реализация1. Retry-on-rollback (автоматический повтор при откате).Это главная особенность pgpro_queue. Если транзакция, в которой было прочитано сообщение, откатывается (например, из-за недоступности внешнего сервиса), сообщение не теряется, а автоматически возвращается в очередь для повторной обработки.Управление. Поведение повторов настраивается как на уровне очереди, так и для каждого сообщения. При создании очереди с помощью CREATE_QUEUE можно задать параметры q_retries (максимальное количество попыток) и q_retrydelay (задержка в секундах перед следующей попыткой).Важный параметр. Для работы механизма повторов необходимо явно указать базу данных в конфигурационном файле postgresql.conf:pgpro_queue.database_with_managed_retry = 'имя_вашей_бд'Без этой настройки сообщения при откате транзакции будут удаляться, а не ставиться на повтор.2. Фильтрация и приоритеты.pgpro_queue позволяет гибко управлять потоком сообщений:Приоритеты. При вставке сообщения с помощью INSERT_MESSAGE можно указать q_msg_priority. Чем ниже значение, тем выше приоритет. Сообщения с более высоким приоритетом обрабатываются в первую очередь.Фильтрация. Функции чтения READ_MESSAGE и READ_MESSAGE_XML принимают параметры q_msg_hfilter и q_msg_pfilter, позволяя извлекать сообщения по содержимому их заголовков или свойств.3. Поддержка форматов JSON и XML.Расширение предоставляет отдельные функции для работы с разными форматами данных, что упрощает интеграцию с различными системами:INSERT_MESSAGE и READ_MESSAGE для JSONB;INSERT_MESSAGE_XML и READ_MESSAGE_XML для XML;READ_MESSAGE_ANY для чтения сообщений любого формата из одной очереди.4. Отложенная обработка.При вставке сообщения можно указать параметр q_msg_enable_time, чтобы задача стала доступна для обработки только при наступлении указанного времени.Что мы положили под капот?В основе расширения pgpro_queue лежит простой и надёжный принцип: сообщения хранятся в обычных таблицах PostgreSQL. Такой подход позволяет использовать всю мощь стандартных механизмов СУБД, включая репликацию и восстановление через WAL-файлы. Каждое сообщение, попавшее в очередь, записывается в WAL, что гарантирует его восстановление даже после аварийного отключения сервера. Ключевая особенность pgpro_queue — это глубокая интеграция с транзакционной моделью PostgreSQL, реализующая механизм retry-on-rollback. Он работает как страховка: если транзакция, обработавшая сообщение, откатывается из-за любой ошибки, pgpro_queue автоматически возвращает это сообщение в очередь для повторной попытки. Это гарантирует, что задача будет считаться выполненной только тогда, когда вся связанная с ней работа успешно зафиксирована в базе данных.Ещё одна сильная сторона pgpro_queue — синергия со встроенным в Postgres Pro Enterprise планировщиком фоновых задач (Scheduler). Этот компонент, работающий как cron внутри базы данных, может запускать периодические родительские задачи, которые, в свою очередь, наполняют очередь подзадачами для асинхронного выполнения. Например, массовую генерацию отчётов для клиентов из разных часовых поясов можно разбить на этапы: основная задача в планировщике создаёт подзадачи для каждого региона, а те, в свою очередь, помещают сообщения в очередь с учётом локального времени.Внешние брокеры, такие как Kafka, справедливо славятся своей «непотопляемостью»: они действительно спроектированы выдерживать серьёзные сбои. Однако эта надёжность относится к самому брокеру в изоляции. В реальной системе слабое звено появляется в точках интеграции, и общая стабильность оказывается зависима от внешних факторов: сети, конфигурации, транзакционной согласованности с базой данных. Но pgpro_queue исключает эти риски: очереди живут в той же экосистеме, что и данные приложения. Сообщения не теряются при сбоях, так как их сохранность гарантируется механизмами репликации и восстановления СУБД. Администраторам больше не нужно настраивать отдельные системы мониторинга для очередей: всё управляется через знакомые инструменты PostgreSQL.Важные технические особенностиДля корректной работы с pgpro_queue специалистам следует учитывать несколько моментов:Уровень изоляции. Расширение может использоваться только в транзакциях с уровнем изоляции READ COMMITTED.Подготовленные транзакции. При использовании двухфазного коммита (2PC) есть нюансы. Если транзакция с READ_MESSAGE() подготавливается через PREPARE TRANSACTION, сообщение блокируется до выполнения COMMIT PREPARED или ROLLBACK PREPARED. При этом ROLLBACK PREPARED только разблокирует сообщение, но не активирует логику повторных попыток.Что ждет встроенные очереди: дорожная картаРазвитие pgpro_queue сфокусировано на расширении сценариев использования. Уже в ближайших версиях появятся две ключевые возможности:Система подписок (Pub/Sub). Будет реализован механизм, аналогичный Exchange в RabbitMQ. Продюсер сможет отправлять сообщение в «тему», а не в конкретную очередь. Все потребители, подписанные на эту тему, получат свою копию сообщения. Это открывает путь к созданию полноценных событийно-ориентированных архитектур.Callback-уведомления. Появится возможность настроить «обратный вызов» — HTTP-запрос к внешнему сервису при появлении сообщения в очереди. Это позволит СУБД самой инициировать обработку, а не ждать, пока приложение опросит очередь.Функциональность Dead Letter Queue (DLQ) для «отравленных» сообщений также остаётся в планах, но на более долгосрочную перспективу.ЗаключениеДля корпоративных клиентов ключевое преимущество — предсказуемость. Каждое сообщение обрабатывается в рамках транзакций СУБД, что исключает рассогласование данных. Инфраструктура становится проще: вместо набора разнородных сервисов — единая база данных, где очереди, бизнес-логика и планировщик работают как части одного организма.Такие решения идеальны для проектов, где цена ошибки высока: банковские транзакции, медицинские системы, государственные реестры. Если вашему приложению критически важны атомарность операций и минимизация ручного вмешательства, встроенные очереди PostgreSQL — не выбор, а необходимость. Они не просто обрабатывают сообщения, а становятся страховкой от хаоса в мире распределённых систем.Теги:postgresqlkafkakafka apacheброкер сообщенийброкеры сообщенийбазы данныхpostgres propostgres pro enterpriseХабы:Блог компании Postgres ProfessionalSQLPostgreSQLБазы данныхСерверное администрирование",3300,0,0,7 мин,https://habr.com/ru/companies/postgrespro/articles/965632/,10931,1281,5
"Культура «AI-First»: как перестроить мышление команды, чтобы не отстать от рынка",Michael_Jerlis,2025-11-12T22:37:26.000Z,"['Искусственный интеллект', 'Читальный зал', 'Управление проектами *', 'Машинное обучение *', 'Управление персоналом *']","Michael_Jerlis 12 часов назадКультура «AI-First»: как перестроить мышление команды, чтобы не отстать от рынкаУровень сложностиСреднийВремя на прочтение4 минКоличество просмотров683Искусственный интеллектЧитальный залУправление проектами * Машинное обучение * Управление персоналом * МнениеПока одни компании разочаровываются в искусственном интеллекте, другие строят на его основе бизнес-империи. В чем их секрет? Не в деньгах и не в доступе к технологиям, а в особой культуре.Разберемся, как перестать просто использовать ИИ в работе и перейти к мышлению в стиле AI-First, и почему это единственный способ не превратиться в динозавра.Сколько стоит промедлениеВ прошлой статье я рассказал, почему многие компании, которые внедрили ИИ, разочаровались. Это не кликбейт, а суровая реальность: по некоторым оценкам, до 80% ИИ-проектов проваливаются — это вдвое чаще, чем обычные IT-проекты.Проблема не в том, что ИИ не работает. Но если встроить двигатель от гиперкара в телегу, она точно не поедет. Технология требует не просто инвестиций, а ментального сдвига всей команды, от CEO до стажера.Чтобы избежать участи «динозавров» рынка, которые выбывают из гонки из-за медленного внедрения, нужно перестать воспринимать ИИ как инструмент и сделать его фундаментом всех бизнес-процессов.От инструмента к фундаменту: что значит быть AI-FirstТермин «AI-First» ввел в оборот CEO Google Сундар Пичаи в 2016 году, когда объявил о стратегическом развороте компании. Быть AI-First — значит не просто «прикручивать» ИИ к рабочим процессам, а проектировать продукты, операции и принимать решения вокруг возможностей, которые дает искусственный интеллект.Вместо вопроса «как нам использовать ИИ в этом проекте?», стоит задуматься «как ИИ может полностью изменить способ решения этой задачи?». Этот подход помогает перестроить мышление.Исследование RAND выявило 5 ключевых причин провала ИИ-проектов, и почти все они — культурные, а не технические:Непонимание бизнес-проблемы;Нет качественных данных;Фокус на технологии, а не на решении;Слабая инфраструктура;Попытка решить слишком сложные для ИИ задачи.Культура AI-First решает эти проблемы, выстраивая организацию на трех столпах.Три Столпа Культуры AI-FirstСтолп 1: Данные как главный активСтрогие стандарты управления данными (data governance) — это не бюрократия, а необходимое условие для выживания.Посмотри на Netflix: их система рекомендаций, подбор обложек для фильмов и даже решения о съемках новых сериалов — результат глубокого анализа данных. Сервис построил бизнес-модель на данных, и остается на вершине.Компании, которые пренебрегли данными, столкнулись с проблемой «мусор на входе — мусор на выходе», когда ИИ-модели, обученные на некачественных данных, начали принимать ошибочные решения, стоившие миллионы.Столп 2: Поощрение экспериментовПередовые компании создают «ИИ-песочницы» — изолированные среды, где команды могут тестировать гипотезы и прототипы без риска «сломать» основные бизнес-процессы. Так можно быстро проверять идеи, отбрасывать нерабочие и масштабировать успешные. Подход не только ускоряет инновации, но и повышает мотивацию сотрудников, которые видят, что их идеи не уходят «в стол». Если же попытаться внедрить ИИ-решения сразу в боевую среду, это может привести к дорогостоящим провалам и демотивации команды.Столп 3: ИИ-грамотность для всехСамая большая ошибка — считать, что в ИИ должны разбираться только инженеры. В AI-First компании базовая грамотность должна быть у всех: менеджеров, юристов, маркетологов, HR.Крупные компании уже осознали это и запускают массовые программы обучения:КомпанияИнициативаОхватIKEAПрограмма ИИ-грамотности, включая этику ИИ30,000+ сотрудниковJPMorgan ChaseОбязательное обучение prompt engineering для всех новых сотрудниковВсе новые сотрудникиMasterCard8-часовой курс по принципам ответственного ИИ (справедливость, прозрачность)Все сотрудникиВ EMCD каждый новый сотрудник проходит вводный ИИ-тренинг, а раз в неделю можно посещать лекции и воркшопы, чтобы освоить конкретные инструменты, облегчить рутину, автоматизировать отчеты и упростить коммуникацию.Когда вся команда говорит на одном ИИ-языке, рождаются самые сильные идеи. Маркетолог может предложить новый способ сегментации аудитории, юрист — вовремя заметить риски в использовании данных.Рынок труда и AI-FirstAI-First культура — это не только про эффективность, но и про найм самых талантливых кадров. Зарплаты в сфере ИИ на 67% выше, чем у традиционных разработчиков, а дефицит огромный — до 68% компаний говорят, что им не хватает кадров.Лучшие специалисты не пойдут в компанию, где им придется месяцами выбивать доступ к данным, где боятся экспериментов, а руководство не понимает, чем они занимаются. Они ищут среду, где можно реализоваться. Они ищут AI-First культуру.И здесь — важный нюанс. Мы в EMCD ищем не просто кодеров, а людей, которые умеют решать конкретные бизнес-задачи с помощью ИИ. Поделюсь случаем.Один из наших сервисов постоянно проседал под нагрузкой, и команда долго пыталась найти причину. Стандартные методы не давали результата.Новый разработчик попробовал вместо ручного анализа скормить данные ИИ-модели. Она выявила повторяющиеся паттерны, которые всегда предшествовали сбоям. После этого осталось добавить механизм предиктивного распределения нагрузки, и проблема исчезла полностью.Парень не был «сильнее» как программист, но мыслил в парадигме AI-First.Не стань динозавромЕсли не в этом, то в следующем году компании разделятся на два типа: те, кто смог перестроить культуру и сделал ИИ частью ДНК, и все остальные.Культура AI-First про здравый смысл: учить людей, пересобирать процессы, поощрять эксперименты и фиксировать лучший опыт внутри команды. Чем раньше начать, тем больше шансов не остаться вне игры через несколько лет.Поделись, как внедряешь ИИ в своей команде, и какие еще есть способы перейти на AI-First мышление?Теги:ai-firstии-стартапии в бизнесецифровая трансформацияцифровая трансформация бизнесаавтоматизация процессовИИ-песочницыобучение ииdata governanceИИ в бизнес-процессахХабы:Искусственный интеллектЧитальный залУправление проектамиМашинное обучениеУправление персоналом",683,0,0,4 мин,https://habr.com/ru/articles/965874/,6098,780,5
Эластик и проблемы хранения ленты операций,shoshana_kv,2025-11-12T15:35:02.000Z,"['Блог компании ОТП Банк', 'Финансы в IT']","shoshana_kv 19 часов назадЭластик и проблемы хранения ленты операцийУровень сложностиСреднийВремя на прочтение11 минКоличество просмотров475Блог компании ОТП БанкФинансы в ITКейсПривет, меня зовут Екатерина, я работаю в ОТП Банке на позиции Senior-разработчика в одном из трайбов. В продолжение предыдущей статьи мы вместе с Александром, главным solution-архитектором, расскажем о вызовах, с которыми столкнулись при внедрении нереляционного хранилища в наше ДБО.В ОТП в первую очередь думают об удобстве клиента. Использование современных отказоустойчивых систем, таких как Elasticsearch, — один из важных трейд-оффов: с одной стороны, мы повышаем скорость и качество клиентского опыта, с другой — усложняем архитектуру и сталкиваемся с проблемами, которых не было бы при более простом подходе. Все это работает на эту цель.В этой статье мы поделимся частью таких кейсов и расскажем, как наша команда их решала.Задача: современная лента операцийПеред нами стояла задача создать ленту операций, которая соответствовала бы трем ключевым требованиям:  Высокая производительность: Быстрый доступ к клиентским транзакциям при больших объемах данных.Гибкий поиск: Поддержка полнотекстового поиска и фильтрации.Масштабируемость по глубине данных: Возможность работы с разной глубиной истории операций.Мы рассмотрели несколько архитектурных подходов и проанализировали подходящие для них технологии.Вариант 1: Реляционная база данных с кешем Суть подхода: Классическая связка базы данных (например, PostgreSQL) и горячего кеша в памяти для оперативных данных.Почему отказались: Главная проблема — глубина поиска данных. Глубина поиска для выписок может составлять от нескольких дней до нескольких лет. Хранить многолетний кеш для всех клиентов крайне ресурсоёмко с точки зрения оперативной памяти. При горизонтальном масштабировании пришлось бы либо использовать отдельное распределенное кеш-хранилище (например, Redis), что усложняет архитектуру, либо механизм sticky sessions, от которого мы хотели уйти. Этот подход хорошо справляется с недавними данными, но не подходит для эффективного поиска по полной истории.Кроме того, по результатам множества бенчмарков, системы вроде Elasticsearch показывают значительно более высокую скорость выполнения сложных поисковых запросов по большим datasets по сравнению с реляционными СУБД.Вариант 2: ClickHouse Суть подхода: Использование колон��чной аналитической СУБД, оптимизированной для быстрого чтения.Почему отказались: ClickHouse отлично подходит для аналитических отчетов, но оказался неудобен для нашей онлайн-системы по нескольким причинам:Сложность эксплуатации: Требует глубоких знаний для поддержки и тонкой настройки.Ограничения на обновления: Отсутствие привычной поддержки точечных UPDATE. Клиентские операции часто обновляются (например, баланс карты может меняться многократно за день), что в ClickHouse приводит к необходимости замены всей записи. Это ведет к высокой фрагментации данных и снижению производительности.Вариант 3: ElasticsearchСуть подхода: Использование поискового движка, заточенного под работу с большими объемами неструктурированных данных.Почему выбрали: Этот вариант наилучшим образом соответствовал нашим требованиям:Скорость поискаВстроенная морфология и поддержка нечеткого (fuzzy) поискаПроизводительность на больших данных: Система стабильно работает с миллиардами документов, в то время как запросы аналогичной сложности в SQL-базах могут выполняться неприемлемо долго.Гибкость схемы: Данные хранятся в виде JSON-документов, возможность создавать динамический маппингМасштабируемость: Поддержка шардирования и репликации реализована на уровне платформы, что избавляет от необходимости разработки кастомных решений.Итог: После анализа мы остановились на Elasticsearch как на наиболее сбалансированном решении. Стоит отметить, что на момент принятия решения у команды не было практического опыта работы с этой технологией. Поэтому процесс внедрения сопровождался как успешными находками, так и преодолением трудностей, о которых мы подробнее расскажем в следующих разделах.Проблема 1. Производительность Elasticsearch и количество индексовВ Elasticsearch данные организованы в индексы, которые, в свою очередь, делятся на шарды. Изначально мы выбрали простую и логичную схему: выделить отдельный индекс для каждой организации (клиента). На старте, при небольшом количестве клиентов, система работала идеально, обеспечивая мгновенный отклик.Однако с ростом числа клиентов мы столкнулись с фундаментальным ограничением Elasticsearch: производительность критически падает при большом количестве индексов и шард. Согласно официальной документации, для одного узла не рекомендуется превышать лимит в 1000 шард [источник]. Хотя этот лимит можно увеличить, сама компания Elastic предупреждает, что это временное решение, и стабильная работа не гарантируется [источник].На практике деградация проявилась быстро: время операций (например, реиндексации документов) выросло до ~200 мс. Для высоконагруженной системы с SLA в десятки миллисекунд такие показатели стали неприемлемыми.Расчет допустимого количества индексовЧтобы найти решение, мы рассчитали верхнюю границу количества индексов для нашей инфраструктуры. Исходили из следующей логики:Конфигурация одного индекса: 8 шард (для горизонтального масштабирования) × 4 реплики (для отказоустойчивости) = 32 шарда на индекс.Общий лимит для нашего кластера из 4 узлов: ~4000 шард.С учетом запаса на миграции и техническое обслуживание мы задействовали только треть от общего лимита: ≈1300 шард.Поделив 1300 на 32, мы получили максимум ~40 индексов. Стало очевидно, что первоначальная схема «один индекс на организацию» нежизнеспособна на долгосрочную перспективу.Поиск оптимальной стратегииМы рассмотрели несколько путей оптимизации структуры индексов:Объединение мелких организаций в общие индексы.Почему отказались: Невозможно надежно прогнозировать объем транзакций компании. Маленький клиент сегодня мог стать крупным завтра, создавая дисбаланс нагрузки в общем индексе.Разбивка данных по временным интервалам (например, по месяцам).Почему отказались: Этот подход усложняет архитектуру, так как поиск по истории операций потребовал бы отправки множественных запросов (multisearch) к нескольким индексам. Это сделало бы время отклика непредсказуемым и увеличило бы нагрузку на кластер.Разбивка по регионам.Почему отказались: Деление оказалось слишком крупным и неравномерным, что не решало проблему эффективного распределения нагрузки.В итоге мы выбрали стратегию равномерного распределения организаций по фиксированному пулу индексов. Этот подход позволил нам жестко контролировать общее количество индексов (в пределах рассчитанного лимита в 40 штук), обеспечивая предсказуемую производительность, отказоустойчивость и простоту масштабирования.Скрытый текстpublic void init() {
       final var indexes = indexRepository.findAll().stream()
           .collect(Collectors.toMap(OrganizationIndex::getOrganizationId, Function.identity()));
       INDEX_BY_ORGANIZATION_ID_MAP.putAll(indexes);
   }    
 
    /**
    * При запросе на регистрацию присваиваем организации индекс (по очереди)
    */
   @Transactional
   public void initializeOrganization(final UUID organizationId) {
       init();
       // горячий кеш с данными индексов и организаций
       if (INDEX_BY_ORGANIZATION_ID_MAP.containsKey(organizationId)) {
           return;
       }
       final int organizationsCount = (int) indexRepository.count();
       // номер индекса - остаток от деления на количество организаций
       final var indexName = getIndexName(organizationsCount % indexCount + 1);
       final var index = indexRepository.save(OrganizationIndex.of(organizationId, indexName, OrganizationIndexStatus.READY));
       INDEX_BY_ORGANIZATION_ID_MAP.put(organizationId, index);
       log.info(""Add organization to index {}"", index);
   }Проблема 2. Дублирование данных и конкурентные обновленияКлиентские операции в нашей системе могут создаваться через несколько независимых каналов:Обращение в офис;Новое ДБО (дистанционное банковское обслуживание);Старое ДБО;Внутренние операции.После создания событие проходит через цепочку промежуточных сервисов и финализируется в АБС. Критически важным моментом стало то, что обновление одной и той же операции могло быть инициировано разными системами параллельно. На практике это вылилось в ситуацию, когда обновления для одного документа в Elasticsearch приходили одновременно из разных источников — через REST-API и несколько Kafka-топиков.Почему стандартные механизмы Elasticsearch не подходятПопытка обновлять данные «в лоб» привела к потере изменений. Причина в том, что Elasticsearch не гарантирует строгой консистентности (immediate consistency) на уровне отдельных документов. Даже принудительное обновление индекса после записи с помощью withRefreshPolicy(RefreshPolicy.IMMEDIATE) не защищает от race condition (гонки состояний) между параллельными запросами.В отличие от реляционных СУБД, в Elasticsearch отсутствуют механизмы строгой блокировки на уровне записи (row-level locking) в рамках транзакции. В результате конкурентные операции update могут выполняться на устаревшей версии документа, затирая изменения друг друга.Этап 1: Оптимистическая блокировка (Optimistic Concurrency Control)В качестве первого решения мы реализовали оптимистическую блокировку средствами самого Elasticsearch, используя механизм версий документов (_version). Однако этот метод не сработал в наших условиях. Из-за высокой задержки индексации, вызванной проблемой с большим количеством индексов (см. предыдущий раздел), обновления приходили быстрее, чем успевала обновляться версия документа в индексе. Это приводило к лавине ошибок конфликта, и большая часть обновлений не применялась.Этап 2: Специализированный сервис-агрегатор и синхронизация через RedisМы пришли к выводу, что нужен централизованный механизм синхронизации, вынесенный за пределы Elasticsearch. Для этого был разработан отдельный сервис-агрегатор, который выполняет следующие функции:Принимает события из всех источников (REST, Kafka-топики).Приводит их к единому формату данных.Определяет приоритет обработки для событий из разных каналов.Вводит небольшие искусственные задержки для выравнивания нагрузки.Таким образом, разнородные операции превращались в упорядоченный поток событий с единым идентификатором.Для синхронизации параллельных обращений к одному и тому же идентификатору операции и сохранения stateless-архитектуры самого агрегатора мы использовали Redis в качестве распределенного кэша и легковесного координатора:Ключ: Идентификатор операции.Значение: Временная метка последнего принятого обновления.Скрытый текстpublic void handle(final TransactionUpdate transactionUpdate) {
    final var startTime = System.currentTimeMillis();
    // transactionUpdate - это класс wrapper, который оперирует идентификаторами операций
    transactionUpdate.message().getUpdateIds().forEach(updateId -> {
        try {
            // делаем лок в redis c максимальным временем обработки  - 1 минута
            redisLockRegistry.executeLocked(
                updateId,
                Duration.ofMillis(lockTimeoutMs),
                () -> {
                     // в связи с тем, что нужно дать время elasticsearch обновить индексы, то вычисляем время ожидания для операций, которые одновременно обновляются из разных источников
                    final long timeToWait = getTimeToWaitAndUpdateCache(updateId);
                    if (timeToWait <= 0) {
                        process(transactionUpdate, updateId);
                        return;
                    }
                    Thread.sleep(timeToWait);
                    process(transactionUpdate, updateId);
                });
        } catch (Exception e) {
            log.error(""Error while processing update transaction {}, in: {}"", updateId, timeDurationFrom(startTime), e);
            throw new UnexpectedException(""Error while processing update transaction"");
        }
    });
    log.info(""Transaction message was processed in: {}"", timeDurationFrom(startTime));
}
 
public long getTimeToWaitAndUpdateCache(final String updateId) {
    // ищем в редисе последнее время обновления операции
    final var savedLastUpdateTime = transactionLastUpdateRepository.findById(updateId)
        .map(TransactionLastUpdate::getLastUpdateTime)
        .orElse(null);
    // получаем время для начала обновления
    final var newLastUpdateTime = calculateUpdateTime(savedLastUpdateTime);
    // обновляем данные в кеше redis
    transactionLastUpdateRepository.save(TransactionLastUpdate.builder()
        .updateId(updateId)
        .lastUpdateTime(newLastUpdateTime)
        .ttl(lastUpdateCacheTtlSec)
        .build());
    long timeToWait = newLastUpdateTime - System.currentTimeMillis();
    log.debug(""Calculate time to wait: id {}, new update time {}, time to wait {}"",
        updateId, newLastUpdateTime, timeToWait);
    return timeToWait;
}
 
private long calculateUpdateTime(@Nullable final Long lastUpdateTime) {
    // операцию еще не обновляли или обновляли в прошлом (раньше, чем delayMilliSeconds назад), значит можно обновлять сразу
    if (isReadyForProcess(lastUpdateTime)) {
        return System.currentTimeMillis();
    }
    // в ином случае надо ожидать
    return lastUpdateTime + delayMilliSeconds;
}
 
private boolean isReadyForProcess(@Nullable final Long lastUpdateTime) {
    return lastUpdateTime == null || lastUpdateTime < System.currentTimeMillis() - delayMilliSeconds;
}
 
 
 private void process(final TransactionUpdate transactionUpdate, final String updateId) {
    // по типу источника информации понимаем, какой пришел формат данных, и применяем необходимые операции к нему
    switch (transactionUpdate.type()) {
        case TYPE_1 -> service1.process(transactionUpdate);
        case TYPE_2 - > service1.process(transactionUpdate, updateId);
        .....
        default -> throw new UnsupportedOperationException(""Unknown update type "" + transactionUpdate.type());
    }
}
Это решение позволило эффективно справляться с параллельными обновлениями и стало временным решением проблемы.Этап 3: Гарантия порядка с помощью Kafka и унификация форматаРешение с сервисом-агрегатором и Redis было работоспособным, но добавляло сложность: необходимость поддерживать отдельный сервис и инфраструктуру кэша. Мы решили пересмотреть архитектуру потоков данных, чтобы найти более фундаментальное и простое решение.Проблемы предыдущего подхода:Разнородность форматов: Источники продолжали генерировать события в разных структурах данных.Нарушение последовательности: Не было гарантии, что обновления одной операции придут в агрегатор в правильном хронологическом порядке.Архитектурные измененияМы провели ряд ключевых изменений, переведя взаимодействие на Apache Kafka:Kafka с ключом сообщенияВ качестве ключа каждого сообщения стал использоваться идентификатор операции. Это фундаментальное изменение, так как Kafka гарантирует порядок доставки сообщений с одним и тем же ключом в рамках одной партиции. Это решило проблему конкурентных обновлений на транспортном уровне, устранив саму возможность нарушения последовательности.Единый унифицированный форматМы разработали и внедрили единый контракт для событий об операциях. Все системы-источники стали публиковать сообщения только в этом формате. Это позволило упростить логику агрегатора, который теперь мог напрямую десериализовать и обрабатывать входящие события без дополнительных преобразований.Консолидация топиковВместо множества специализированных топиков для каждого сервиса мы ввели единый топик для событий, связанных с операциями. Это сместило фокус: теперь не каждый сервис диктовал свой формат, а агрегатор определял единый контракт для всего потока данных.РезультатБлагодаря этим изменениям нам удалось полностью отказаться от механизма синхронизации через Redis. Новый подход обеспечил:Предсказуемость: Порядок обработки гарантирован средствами Kafka.Упрощение архитектуры: Исчезла необходимость в поддержке отдельного кэша и логики разрешения конфликтов.Повышение надежности: Система стала менее зависимой от дополнительных компонентов.Минимальная компонентная архитектура разверткиВ качестве итога приведем минимальную рабочую, по нашему мнению, архитектуру кластера Elasticsearch, разработанную для следующих условий:Инфраструктура: 2 основных ЦОДа с кластерами Kubernetes и микросервисами.Ограничение: 1 дополнительный ЦОД для кворума с ограниченными ресурсами.Схематичное изображение финальной архитектуры представлено ниже.Для начала кратко обозначим роли нод, которые мы использовали:Мастер-нода (Master Node): Формирует кворум, управляет состоянием кластера (метаданные, шардирование), обеспечивает консистентность и защиту от split-brain. Не хранит данные и не обрабатывает пользовательские запросы.Координирующая нода (Coordinating Node): Принимает запросы от микросервисов на чтение и запись, маршрутизирует их к нужным data-нодам и агрегирует результаты. Является входной точкой в кластер.Data-нода (Data Node): Хранит данные, выполняет поиск, агрегацию и другие операции непосредственно с индексами.Выбранная конфигурацияИсходя из требований отказоустойчивости и производительности, мы развернули кластер следующей конфигурации:Координирующие ноды: По 1 ноде в каждом из 2 основных ЦОДов. Это обеспечивает минимальные задержки для микросервисов, которые обращаются к координатору в своем ЦОДе.Мастер-ноды: 3 ноды, распределенные по трем ЦОДам. Это гарантирует работоспособность кворума (требуется большинство, т.е. 2 из 3) даже при полном отказе одного из основных ЦОДов. В случае сетевого разрыва кластер запретит запись на изолированном участке, но сохранит доступность данных для чтения.Data-ноды: 4 ноды в основных ЦОДах. Это минимальное количество для эффективного шардирования, которое можно легко увеличить для горизонтального масштабирования.ИтогПредставленная архитектура позволила нам построить отказоустойчивую и надежную систему, которая соответствует строгим требованиям бизнеса к доступности и производительности. Она устойчива к сбоям на уровне ЦОДа и предоставляет четкий путь для дальнейшего масштабирования хранилища данных.Теги:elasticsearchjavaarchitectureфинтехинтеграцииХабы:Блог компании ОТП БанкФинансы в IT",475,0,8,11 мин,https://habr.com/ru/companies/otpbank/articles/965420/,18221,1996,2
"Нечёткий поиск при пересечении множеств, или Как выжать все соки из Хэширования по сигнатуре",VGoren,2025-11-13T07:16:06.000Z,"['SQL *', '.NET *', 'C# *', 'Microsoft SQL Server *', 'Алгоритмы *']","VGoren 4 часа назадНечёткий поиск при пересечении множеств, или Как выжать все соки из Хэширования по сигнатуреУровень сложностиСреднийВремя на прочтение23 минКоличество просмотров265SQL * .NET * C# * Microsoft SQL Server * Алгоритмы * Из песочницыСлияние рек Солимоэнс (верхняя Амазонка) и Риу-Негру в БразилииНа просторах интернета легко можно найти материалы по реализации нечёткого поиска, в которых предполагается поиск одной строки в множестве строк M. Но что если возникнет необходимость реализовать нечёткое сравнение множества M₁ с множеством M₂? При классическом подходе нам придется выполнить  сравнений - при линейном росте этих множеств, сложность задачи будет расти экспоненциально, в плане производительности это решение никуда не годиться!Предложенное ниже решение для БД SQL реализовано с помощью хэширования строк по сигнатуре. Оно максимально эффективно выполняет данный поиск в пределах одной ошибки (по расстоянию Левенштейна), но его можно адаптировать и под поиск в пределах какого угодно количества ошибок, но увеличение допуска экспоненциально усложняет алгоритм.Размер строк также не ограничен, но нечёткий поиск очень большого текста в пределах одной, двух, трёх ошибок можно сравнить со ""сферический конём в вакууме"" (не могу вообразить, зачем это может понадобится), в этом случае гораздо эффективнее воспользоваться другими методами хэширования - например, SimHash(SimilarityHash)[1][2][3], MinHash[1][2]. Поэтому предложенный алгоритм наиболее уместен для поиска средних, малых строк - ФИ, ФИО, VIN, маркировка, спецификация техники, серийные номера, штрихкоды, хэшсуммы и т.д.Цели:Ознакомить с концепциейДать конкретный пример интеграции в БД SQL(MSSQL)Ознакомить с возможностями на базе практической реализацииПример результатов при тестировании пересечения 5000 customers с 5000 employees по условию нечёткого поиска в пределах 2-ух ошибок по расстоянию ЛевенштейнаОсновная концепцияХэш по сигнатуре В целях упрощения восприятия, здесь и далее будем разбираться на примере 32-битного хэша, хотя его размер может быть любым. Кратко описываю алгоритм получения хэша(в практической реализации я буду делать так же):  №  Операция                                                                                                                                                                                                               Результат                                           1  Берем за вводные хэша ASCII код каждой буквы                                                                                                                         значения в диапазоне байта - (1-255)                2  Пропускаем значения через рандомайзер (в моей реализации на C# это Алгоритм генератор случайных чисел D.E. Knuth)  значения в диапазоне int'а - (0-4294967295)  3  Применяем простейший остаток от деления на размер хэша(x32)                                                                                                                                                     значения в диапазоне - (1-32)                       4  В пустой битовой(x32) маске ""включаем"" биты по индексу полученных значений                                                                                                                                             значения в диапазоне байта - (1-255)               Правило 2-ух ошибокСреди всех нечётких хэшей он обладает уникальной особенностью, на которой будет строиться вся дальнейшая работа - он подчиняется ""правилу 2-ух ошибок""(для удобства изложения пришлось придумать название самостоятельно, в статье Бойцова Л.М. это свойство описано, но названия не получило). Формулировка: Если расстояние Левенштейна между строками А и B = 1, то расстояние Хэмминга между хэшами от А и Б меньше или равно 2, если это была замена, либо меньше или равно 1, если это была вставка/удалениеИными словами:    1 вставка/удаление     не может изменить хэш более чем на 1 ошибку         1 замена               не может изменить хэш более чем на 2 ошибки         ↓                      ↓                                               1 ошибка не может изменить хэш более чем на 2 ошибки Например, получим сигнатурные хэши от 2-ух одинаковых строк с одной ошибкой: СтрокаХэшAЧумаков Максим Глебович00011011 00001100 00101011 01100110BЧубаков Максим Глебович00011011 00001101 00001011 01100110В строке A была вводная м, которая, очевидно, включала бит №19 В строке B пропала вводная м, и появилась вводная б, которая, очевидно, включила бит №16Правило 2-ух ошибок позволяет сделать поиск детерменированным - мы можем быть уверены, что точно не пропустим строки с заданным количеством ошибок. Например, очень популярный и действительно неплохо работающий даже на таких небольших строках, как ФИО, SimHash все равно остается вероятностным - 1 ошибка скорее всего поменяет мáлую часть хэша, но всегда остается вероятность того, что хэш изменится кардинально. MinHash тоже вероятностный. Они лучше подходят для больших текстов, например, при сравнении на антиплагиат - особенно, если предварительно обработать их, исключив связующие предлоги, союзы, артикли и т.д.HEngineHEngine[1][2] является алгоритмом ускорения поиска запрашиваемой бинарной строки в множестве таких строк в пределах заданного расстояния Хэмминга. Сейчас попробуем применить этот алгоритм для поиска в пределах 2-ух ошибок на нашем примере, попутно раскрывая его суть:Если разделить 32-битные хэши A и B на 4 равные части(chunk'и) по 8 бит с сохранением информации об их порядковом номере, то как минимум по двум из них A и B совпадут:ichunkichunkmatchA000011011B000011011✓A100001100B100001101✗A200101011B200001011✗A301100110B301100110✓То есть необязательно проверять сплошняком каждый бит. Если мы ищем похожие на А строки в множестве М, мы можем таким же образом дробить хэши на 4, 8, 16 частей и искать match'и соответственно по 2/4, 6/8, 14/16, 30/32(собственно расстояние Хэмминга). Постоянно сужая выборку на текущем этапе ""предрасчёта"" расстояния Хэмминга, мы будем компенсировать возрастающую стоимость поиска match'ей на следующем этапе (очевидно, что проверить 2/4 легче, чем 30/32).Более того, если мы ищем строки из M₁, похожие на строки M₂ с расстоянием Левенштейна = 1, после первого самого дешевого этапа (2/4), мы уже получаем не просто сокращенные множества от M₁ и M₂, а суженный набор пар M₁.id-M₂.id, которые теоретически могут быть искомыми. Таким образом уже после первого этапа предрасчёта расстояния Хэмминга перед нами стоит задача не экспоненциальной сложности, а линейной.Специфика SQLВот и весь алгоритм - хэшируем по сигнатуре множества M₁, M₂ и ищем совпадения по HEngine (перебирая 2 массива вложенными циклами). Теоретической новизны в проекте практически нет. Осталось написать пару примеров реализации, и на этом можно было бы и закончить, если бы мы программировали на обычном императивном C-подобном языке программирования. Но, как правило, на практике для хранения/выборки данных используются БД SQL. Внедрение этого поиска в SQL оказалось достаточно сложной задачей, в ходе которой сам алгоритм претерпел много изменений, хотя в сущности концепция осталась прежней.Предоставление конкретной реализации нечёткого поиска является одной из целей этой статьи. Реализовано на примере MSSQL. Подобное решение можно портировать на любую СУБД, имеющую возможность интеграции стороннего кода(SQLCLR, PL/Java, PL/Python, MySQL Connector/C++ и др.), без каких-либо ограничений.Необходимость интеграции стороннего кодаСледующие функции очень проблематично реализовать силами процедурного SQL (T-SQL) - производительность будет на плачевном уровне. Поэтому они реализованы через интеграцию стороннего кода (C# SQLCLR)ФункцияНазначениеLevenshteinDistanceString()Принимает 2 строки,       возвращает расстояние Левенштейна между нимиHammingDistanceX32()Принимает 2 int'а по x32, возвращает расстояние Хэмминга между ними, прерывает подсчет расстояния, если оно превысит лимитGetSignatureHash()Возвращает сигнатурный хэш от строкиSplitSignatureHash()Разбивает сигнатурный хэш на chunk'и по x8В SQL нельзя эффективно реализовать алгоритм HEngine полностьюПосле первого самого дешёвого этапа 2/4, перед нами будет множество пар из M₁.id-M₂.id. Если мы начнем дальше ""копать"" согласно этому алгоритму (проходить этапы 6/8, 14/16), то в каждой итерации на каждую пару, нужно будет вызывать дважды(на M₁.id и M₂.id) функцию разбивки хэша SplitSignatureHash(), затем полученные множества придется join'ить. Операционная стоимость даже одной SplitSignatureHash() в любом случае больше, чем одной HammingDistanceX32(), потому что она примитивна и работает через битовый XOR. Очевидно, что проходить этапы 6/8, 14/16 в SQL для дальнейшего сужения выборки бессмысленно - эффективнее сразу вызывать HammingDistanceX32().Базово описываем алгоритм: №ОперацияРезультат1На этапе 2/4 вызываем SplitSignatureHash() для M₁ и M₂линейно растущие множества 2MEGRE/HASH JOIN'им с помощью стандартного SQLэкспоненциально растущее множество 3Агрегируем значения (GROUP BY M₁.Id, M₂.Id HAVING COUNT() >= 2)сокращенное множество комбинаций 4На остаток пар вызываем HammingDistanceX32()сокращенное множество комбинаций 5На остаток пар вызываем LevenshteinDistanceString()искомые комбинации Ускорение с помощью k-комбинаций chunk'ов.6 k-комбинаций 2/4При классическом исполнении алгоритма HEngine, БД тратит огромный ресурс на сложное агрегирование данных(3 этап). Эта операция настолько затратна, что оптимизатор запросов SQLServer'а предпочитает сначала выполнять 4-ый этап, производя много лишних запусков HammingDistanceX32() на несгруппированном множестве, но сокращая множество комбинаций, а затем - 3-ий, потому что так дешевле!Вернемся к нашему примеру. Если A находится в множестве M₁, а B - в M₂. То на 2-ом этапе  с комбинации А-Б в множестве комбинаций M₁.id-M₂.id мы получили 2 строки по 2-ум совпадающим парам chunk'ов по индексам 1 и 4. Но помимо интересной нам комбинации, в полученном несгруппированном множестве находятся как интересные нам комбинаций, которые заjoin'ились более чем по 2-ум chunk'ам, так и НЕинтересные, которые заjoin'ились только лишь по 1-му chunk'у - вот поэтому нам необходим 3-ий этап.Для избежания затратного агрегирования введем функцию стороннего кода SplitSignatureHashKComb() - возвращает все возможные k-комбинации 2/4 chunk'ов по 8 бит:Во-первых, будем возвращать не 2 поля (i, chunk), а сконкатенированное 2-байтовое (i_chunk). Да, для диапазона значений 0-3 достаточно 2 бит, но байт(8 бит) – это минимальная ячейка адресации. На примере A-B это будет выглядеть следующим образом.ii_chunkii_chunkmatchA000000000 00011011B000000000 00011011✓A100000001 00001100B100000001 00001101✗A200000010 00101011B200000010 00001011✗A300000011 01100110B300000011 01100110✓А теперь будем возвращать все возможные k-комбинации i_chunk'ов:k_combi_chunk_k_combii_chunk_k_combmatchA01__00000000 00011011        00000001 00001100B01__00000000 00011011        00000001 00001101✗A0_2_00000000 00011011        00000010 00101011B0_2_00000000 00011011        00000010 00001011✗A0__300000000 00011011        00000011 01100110B0__300000000 00011011        00000011 01100110✓A_12_00000001 00001100 00000010 00101011B_12_00000001 00001101 00000010 00001011✗A_1_300000001 00001100 00000011 01100110B_1_300000001 00001101 00000011 01100110✗A__2300000010 00101011 00000011 01100110B__2300000010 00001011 00000011 01100110✗-: Увеличение веса и количества возвращаемых строк. Раньше на каждый хэш приходилось по  байт, теперь  байт. +: Не нужно агрегировать комбинации, это дает несопоставимо бóльший выигрыш в производительностиОписываем ускоренный окончательный алгоритм, которым будем пользоваться (теперь можно оценить, как далеко мы ушли от первоначального HEngine): №ОперацияРезультат1На этапе 2/4 вызываем SplitSignatureHashKComb() для M₁ и M₂линейно растущие множества 2merge/hash join'им с помощью стандартного SQL, с чем он неплохо справляетсяэкспоненциально растущее множество  исключительно интересных нам комбинаций M₁.Id-M₂.Id3Агрегируем значения (GROUP BY M₁.Id, M₂.Id или DISTINCT)сокращенное множество комбинаций 4На остаток пар вызываем HammingDistanceX32()сокращенное множество комбинаций 5На остаток пар вызываем LevenshteinDistanceString()искомые комбинации Стоит отметить, что:На практике оптимизатор запросов SQLServer'а всё равно предпочитает менять 4-ый и - 3-ий этап местами, но сама агрегация гораздо дешевлеДо 5-го этапа алгоритм обладает свойством резистивности к перестановке слов в строке - порядок в строках не важен(ФИО!=ИФО). Чтобы сохранить это свойство, нам придётся разбивать 5-ый шаг на несколько однотипных расчётов расстояния Левенштейна для каждой комбинации слов в шаблоне(в случае ФИО - это факториал  ). Учитывая, что к 5-му этапу выборка уже максимально сужена, это не несёт слишком больших затрат, хотя, конечно, количество слов в шаблоне усложняет 5-ый этап экспоненциально.DDL vs расчёт на местеРасчёт на местеSQLServer на этапе 2/4 сортирует chunk'и и использует MERGE JOIN, т.е. план адекватныйDDLфактически экономим время на расчет хэшей и сортировку(индексацию)меньше дергаем tempDB(больше свободной ОЗУ)Более предсказуемый план выполнения, т.к. оптимизатор SQLServer'а неадекватно оценивает стоимость SQLCLR-функций - они для него словно ""закрытый ящик"". Например, более дешёвый HammingDistanceX32() имеет бóльший Estimated Operator Cost, чем у LevenshteinDistanceBytes(), потому что имеет больше параметров, несмотря на то, что он примитивнее:HammingDistanceX32() ""дороже"" LevenshteinDistanceBytes()Код запроса:SELECT *
FROM       (SELECT * FROM dbo.employees WHERE dbo.HammingDistanceX32      (id, 25, 32) <= 2) AS t1
INNER JOIN (SELECT * FROM dbo.employees WHERE dbo.LevenshteinDistanceBytes(id, 25)     <= 2) AS t2 ON t1.id = t2.id
Специфика SQL(необязательно к прочтению)Индексные таблицы для 2, 3, 4... этапов HEngineВыше я утверждал, что стоимость SplitSignatureHash() больше одной HammingDistanceX32(), чтобы доказать бессмысленность промежуточных этапов HEngine, но что если мы дополнительно создадим индексированные 6/8, 14/16 таблицы для M₁ и M₂?Если мы будем использовать базовый алгоритм, то всё равно на каждом этапе нам придется выполнять дорогую агрегациюЕсли мы будем использовать ускоренный алгоритм, то количество и размер этих k-комбинаций будет расти экспоненциально, как и затраты на обслуживание индекса.ЭтапКоличество строкВес строки(байт)Вес индекса на строку(байт)2/4646/8281214/1612028В подтверждение словSELECT COUNT(*) FROM SplitSignatureHashKComb(123456, 8, 2)
SELECT COUNT(*) FROM SplitSignatureHashKComb(123456, 4, 6)
SELECT COUNT(*) FROM SplitSignatureHashKComb(123456, 2, 14)
Как минимум, по расходу памяти это неэффективно - алгоритм из п.3 окончательный.super_function()Если мы положим абсолютно всю логику по сравнению хэшей в одну воображаемую super_function() из стороннего кода, то сравнивая M₁.id-M₂.id приемлемой производительности достигнуть не получится, потому что, как уже было сказано, для SQLServer'а эта функция - ""закрытый ящик"". Оптимизатор никак не сможет построить оптимальный план - он будет вызывать super_function()  раз.Если бы мы искали, к примеру, одинаковую длину строк через стандартный LEN(), SQLServer скорее всего:№Операция1посчитает все M₁.id.LEN(), M₂.id.LEN()2отсортирует полученные множества3заmerge join'ит их булевой сортировкой, или накрайняк(если их млрд) заhash join'ит4↓5экспоненциальную задачу  он сведет к линейной Здесь простейший запрос, который невозможно свести к линейной сложности, на котором можно ""прикинуть"" длительность выполнения при использовании super_function(): xor32() - возвращает побитовый XOR двух чисел, это простейшая функция. Она отрабатывает медленнее встроенного ABS() - видимо, дополнительные затраты идут на приведение SQLServer типов к SQLCLR C# типамЗапросDECLARE @start int = 0
DECLARE @end   int = 2000
DECLARE @step  int = 1

;WITH x AS
(
   SELECT n FROM (VALUES (0),(1),(2),(3),(4),(5),(6),(7),(8),(9)) v(n)
),
series AS
(
    SELECT TOP (ROUND((@end- @start) / @step, 0) + 1)
           @start - @step + ROW_NUMBER() OVER(ORDER BY (SELECT NULL)) * @step AS n
    FROM
       x as x1, --1           - 10
       x as x2, --11          - 100
       x as x3, --101         - 1000
       x as x4, --1001        - 10 000
       x as x5, --10 001      - 100 000
       x as x6, --100 001     - 1 000 000
       x as x7, --1 000 001   - 10 000 000
       x as x8, --10 000 001  - 100 000 000
       x as x9  --100 000 001 - 1 000 000 000
)
SELECT *
FROM       series s1
CROSS JOIN series s2
WHERE --ABS(s1.n*s2.n - 305)  = 4056/*random int*/
      dbo.xor32(s1.n, s2.n) = 4056/*random int*/
То есть фактически бóльшая часть экономии стоимости при практической реализации алгоритма достигается за счёт того, что количество вызовов функций SplitSignatureHash() линейно, а задача экспоненциальной сложности - первичный (2/4) предрасчёт расстояния Хэмминга - ложится на плечи SQL, с чем он неплохо справляется с помощью своих инструментов - индексов, merge/hash join'ов и т.д.Почему мы не можем передать внутрь SQLCLR M₁ и M₂ целиком?Таблицы в SQLServer не передаются, придется передавать через XMLСчитаем предположительный вес этой переменной: M₁.N = 100 0001 строка содержит Вес переменной XML как минимум Далее её нужно распарсить и превратить в массивы struct'ур, пригодных для циклической обработки.С M₂.N нужно проделать то же самоеОперирование такими большими переменными будет вынуждать пользоваться кучей и следить за стекомSQLServer сам включает многопоток, в C# придется прописывать вручнуюMEGRE/HASH JOIN не используется, нужно будет внутри сортироватьВ общем слишком много трудозатрат для решения с очень сомнительной производительностью, реализовывать не пробовалСолениеСолениеВ этом разделе возможно есть немного теоретической новизны(по крайней мере для русскоязычного интернета). При классическом хэшировании по сигнатуре, если строки разные, но имеют одинаковый набор уникальных букв, случится коллизия.Например Строка                          Уникальные вводные  Чумаков Максим Глебович  Ч,у,м,...м,...б     Чубаков Максим Глебович  Ч,у,б,...м,...б    Хэш должен быть качественным - обладать свойствами устойчивости к коллизиям, которые гарантируются нормальным распределением битов в битовой маске. Иначе на этапе 2/4 будет много лишних join'ов, что негативно скажется на производительности. Чтобы повысить его качество были предприняты попытки его дополнительно посолить(добавить в хэш больше уникальной информации о строке). Пробовались следующие соли, которые применялись к каждой вводной(букве) хэша:Нарушающие правило 2-ух ошибокКоличество повторений буквы во всей строкеЗамена повторяющейся буквы не может изменить хэш более чем на 4 ошибкиНапример Строка                          Уникальные вводные      Чумаков Максим Глебович  Ч*1,у*1,м*2,...б*1,...  Чубаков Максим Глебович  Ч*1,у*1,б*2,...м*1,... Количество повторений буквы в словеЗамена повторяющейся буквы в пределах слова, если нет такой же буквы с таким же кол-вом повторений в другом слове(нет такой же вводной) не может изменить хэш более чем на 4 ошибкиНапример Строка                               Уникальные вводные  Колокольцев Максим Глебович   ...л*2.........     Корокольцев Максим Глебович   ...р*1...л*1...     Колокольцев Максим Гарриевич  ...л*2...р*2...     Корокольцев Максим Гарриевич  ...р*1...р*2...    N-gramm'ыЗамена повторяющейся буквы не может изменить хэш более чем на  ошибки.Например Строка                          Уникальные вводные по 2-gramm'ам  Чумаков Максим Глебович  ...ум, ма...                      Чубаков Максим Глебович  ...уб, ба...                     Вывод:Эти соли усиливают селективность хэша, но увеличение предела допустимых ошибок в хэше экспоненциально негативно влияет на производительность:Количество ошибокЭтапКоличество строкВес строки(байт)Вес индекса на строку(байт)12/4642416/82812336114/1612028336024/8708560212/161820244368032/8284112310/16800820160160В подтверждение слов          SELECT '1' AS lev_dist,'2/4' AS stage, COUNT(*) AS cnt, MAX(LEN(iChunkKComb)) AS kComb_size, COUNT(*) * MAX(LEN(iChunkKComb)) AS row_size FROM dbo.SplitSignatureHashKComb(123456, 8, 2)  
UNION ALL SELECT '1',            '6/8',          COUNT(*),        MAX(LEN(iChunkKComb)),               COUNT(*) * MAX(LEN(iChunkKComb))             FROM dbo.SplitSignatureHashKComb(123456, 4, 6)  
UNION ALL SELECT '1',            '14/16',        COUNT(*),        MAX(LEN(iChunkKComb)),               COUNT(*) * MAX(LEN(iChunkKComb))             FROM dbo.SplitSignatureHashKComb(123456, 2, 14) 
UNION ALL SELECT '2',            '4/8',          COUNT(*),        MAX(LEN(iChunkKComb)),               COUNT(*) * MAX(LEN(iChunkKComb))             FROM dbo.SplitSignatureHashKComb(123456, 4, 4)  
UNION ALL SELECT '2',            '12/16',        COUNT(*),        MAX(LEN(iChunkKComb)),               COUNT(*) * MAX(LEN(iChunkKComb))             FROM dbo.SplitSignatureHashKComb(123456, 2, 12) 
UNION ALL SELECT '3',            '2/8',          COUNT(*),        MAX(LEN(iChunkKComb)),               COUNT(*) * MAX(LEN(iChunkKComb))             FROM dbo.SplitSignatureHashKComb(123456, 4, 2)  
UNION ALL SELECT '3',            '10/16',        COUNT(*),        MAX(LEN(iChunkKComb)),               COUNT(*) * MAX(LEN(iChunkKComb))             FROM dbo.SplitSignatureHashKComb(123456, 2, 10) 
Но, тем не менее, они могут пригодиться, если мы хотим осуществить ""поверхностный/быстрый"" поиск. Эти соли значительно ускоряют алгоритм, но становится возможным пропуск искомых совпадений. Появляется уязвимость - можно целенаправленно изменить строку так, чтобы получить ложноотрицательный результат совпадения.Сохраняющие правило 2-ух ошибокОтбирать буквы определенного количества повторений.Замена повторяющейся буквы не может изменить хэш более чем на 2 ошибки, но теряет информацию.Например Строка                              Уникальные вводные с кол-вом 2        Колокольцев Максим Глебович  ...л*3...к*2...е*2, в*2...и*2  Корокольцев Максим Глебович  ...   л*2    ...к*2...е*2, в*2...и*2  Колокольцев Максим Глебович  ...л*3...   к*2                Кококольцев Максим Глебович  ...   л*2    ...к*3 Есть идея использовать как двойной хэш, например, хэш от букв с кол-вом 1 + хэш от букв с кол-вом 2. Они вместе дают неплохую селективность, но затраты на поиск по двойному хэшу тоже значительны - придётся выборку от хэша №1 intersect'ить с выборкой от хэша №2.Индекс словаЗамена повторяющейся буквы не может изменить хэш более чем на 2 ошибки, но теряется свойство резистивности к перестановке слов в строке.Например Строка                              Уникальные вводные с кол-вом 2  Колокольцев Максим Глебович  ...л*1...л*1...и*2...и*3        Корокольцев Максим Глебович  ...р*1...л*1...и*2...и*3       Колокольцев Максим Глебович  ...К*1...                      Сококольцев Максим Глебович  ...С*1...                      Вывод: Если нам НЕ нужна резистивность к перестановке слов в строке, то соль по индексу слова считаю наиболее перспективной.Погружение в кодКак вы уже поняли из всего вышеизложенного материала, я достаточно много ""игрался"" с размером хэша, k-комбинаций, солями. Объём DDL, который мне пришлось бы писать вручную параллельно дорабатывая ""шаблон"" создания индекса изначально меня насторожил. Поэтому я сразу прибег к динамическому SQL, который в конечном счёте получился достаточно громоздким, страшным, но работающим. В конце концов, для меня главное - дать пример реализации и представление о производительности интегрированного в SQL алгоритма. Шаблон не умеет реализовывать:резистивность к перестановке слов в строке - это перегрузило бы и без того перегруженный шаблонизатор DDL'а, это можно дописать вручную при необходимости на готовый шаблон. Все нижележащие тесты проводятся без реализации этого свойства, но это не помешает сравнительному анализу хэшей.двойной/тройной хэш - это перегрузило бы и без того перегруженный шаблонизатор DDL'а, это можно дописать вручную при необходимости на готовый шаблон. Вручную дописанный в тестах показал себя неудачно.Шаблон умеет:создавать индекс с несколькими однотипными солями:classic - без солиsalt_cnt - количество повторений буквы во всей строкеsalt_cnt_per_word - количество повторений буквы в словеsalt_i_word - индекс словасоздавать индекс с несколькими хэшами с разными фильтрами вводных - для соли с отбором букв определенного количества повторенийЯ не буду здесь объяснять, как именно работает инструмент - не вижу смысла лезть в дебри генератора SQL'а - я базово опишу, что он делает и покажу как им пользоваться:Допустим, нам нужно осуществить нечёткий поиск между двумя однотипными таблицами customers и employees по шаблону first_name + '%' + patronomyc_name + '%' + last_namecustomers, employeesCREATE TABLE dbo.customers
(
    id              int IDENTITY(1, 1) PRIMARY KEY,
    first_name      nvarchar(100),
    patronomyc_name nvarchar(100),
    last_name       nvarchar(100),
    gender          nchar(1)
)
CREATE TABLE dbo.employees
(
    id              int IDENTITY(1, 1) PRIMARY KEY,
    first_name      nvarchar(100),
    patronomyc_name nvarchar(100),
    last_name       nvarchar(100),
    gender          nchar(1)
)
Для этого нам понадобятся 2 процедуры - create_SH_fuzzy_search_index и create_SH_fuzzy_search_joincreate_SH_fuzzy_search_indexПредназначена для создания индекса на конкретную таблицу. На примере customers 1-граммный 32-битный индекс этапа 2/4 (8-битные chunk'и) без солей(classic) состоит из:Таблицы для хэша с внешним ключом на customers[ix].[customers_full_name_H_1gram_x32]CREATE TABLE [ix].[customers_full_name_H_1gram_x32]
(
     [row_num] int NOT NULL
    ,[classic] varbinary(4)
    ,CONSTRAINT [PK_customers_full_name_H_1gram_x32]                      PRIMARY KEY ([row_num])
    ,CONSTRAINT [FK_customers_full_name_H_1gram_x32.row_num-customers.id] FOREIGN KEY ([row_num]) REFERENCES [dbo].[customers]([id]) ON DELETE CASCADE
)
Таблицы для k-комбинаций chunk'ов от хэша с внешним ключом на таблицу для хэша и индексами - это основная таблица, по которой будет идти первичный поиск этапа 2/4[ix].[customers_full_name_H_1gram_x32_C_x8_K_2/4]CREATE TABLE [ix].[customers_full_name_H_1gram_x32_C_x8_K_2/4]
(
     [row_num] int NOT NULL
    ,[classic] varbinary(4)
    ,CONSTRAINT [FK_customers_full_name_H_1gram_x32_C_x8_K_2/4.row_num-customers_full_name_H_1gram_x32.row_num] FOREIGN KEY ([row_num]) REFERENCES [ix].[customers_full_name_H_1gram_x32]([row_num]) ON DELETE CASCADE
)
CREATE CLUSTERED INDEX [customers_full_name_H_1gram_x32_C_x8_K_2/4.row_num] ON [ix].[customers_full_name_H_1gram_x32_C_x8_K_2/4] ([row_num])
CREATE INDEX [customers_full_name_H_1gram_x32_C_x8_K_2/4.classic] ON [ix].[customers_full_name_H_1gram_x32_C_x8_K_2/4] ([classic])
3.Триггер на customers для заполнения таблицы для хэша. Стоит отметить, что он достаточно умный:не триггериться на строки, у которых template не изменился, чтобы не замедлять update'ы в таблице, если они не меняют templateне включает в индекс строки, у которых пустой template - множество таких строк замедляет работу алгоритма, т.к. хэши от таких template'ов одинаковы -> появляются неуникальные значения -> селективность падает[dbo].[TR_customers_full_name_H_1gram_x32]-- generated in dbo.p_create_SH_fuzzy_search_index
ALTER TRIGGER [dbo].[TR_customers_full_name_H_1gram_x32]
   ON [dbo].[customers]
   AFTER INSERT, UPDATE
AS
BEGIN
    SET NOCOUNT ON;

    DELETE FROM [ix].[customers_full_name_H_1gram_x32]
    WHERE row_num IN
    (
    SELECT I.id
    FROM      (SELECT id, ISNULL(first_name, '') + '%' + ISNULL(patronomyc_name, '') + '%' + ISNULL(last_name, '') AS template FROM Inserted) I
    LEFT JOIN (SELECT id, ISNULL(first_name, '') + '%' + ISNULL(patronomyc_name, '') + '%' + ISNULL(last_name, '') AS template FROM Deleted)  D ON D.id        = I.id
                                                                                                                                               AND D.template <> I.template
    WHERE D.id IS NOT NULL -- changed rows
    )

    INSERT INTO [ix].[customers_full_name_H_1gram_x32] ([row_num], [classic])
    SELECT I.id
          ,dbo.GetSignatureHash(I.template, 1, '%', 65001, 0/*classic*/, 0, 32)
    FROM      (SELECT id, ISNULL(first_name, '') + '%' + ISNULL(patronomyc_name, '') + '%' + ISNULL(last_name, '') AS template FROM Inserted) AS I
    LEFT JOIN (SELECT id, ISNULL(first_name, '') + '%' + ISNULL(patronomyc_name, '') + '%' + ISNULL(last_name, '') AS template FROM Deleted)  AS D ON D.id        = I.id
                                                                                                                                                  AND D.template <> I.template
    LEFT JOIN [ix].[customers_full_name_H_1gram_x32]                                                                                          AS H ON H.row_num   = I.id
    WHERE (   D.id       IS NOT NULL  -- changed rows
           OR H.row_num  IS     NULL) -- haven't been inserted yet
      AND REPLACE(I.template, '%', '') <> ''
END
4.Триггер на таблицу для хэша для заполнения таблицы k-комбинаций хэша[ix].[TR_customers_full_name_H_1gram_x32_C_x8_K_2/4]-- generated in dbo.p_create_SH_fuzzy_search_index
ALTER TRIGGER [ix].[TR_customers_full_name_H_1gram_x32_C_x8_K_2/4]
   ON [ix].[customers_full_name_H_1gram_x32]
   AFTER INSERT, UPDATE
AS
BEGIN
    SET NOCOUNT ON;

    DELETE FROM [ix].[customers_full_name_H_1gram_x32_C_x8_K_2/4] WHERE row_num IN (SELECT row_num FROM Inserted)

    INSERT INTO [ix].[customers_full_name_H_1gram_x32_C_x8_K_2/4] ([row_num], [classic])
    SELECT [row_num], [classic].iChunkKComb
    FROM Inserted
    CROSS APPLY dbo.SplitSignatureHashKComb([classic], 8, 2) AS [classic] WHERE  [classic].i = [classic].i 
END
После всех манипуляций нам остается лишь ""дёрнуть"" за любое поле customers следующим образом UPDATE dbo.customers SET Gender = Gender WHERE 1 = 1 и индекс заполнится по цепочке: 1.UPDATE 2.Триггер на customers  заполнит таблицу для хэша 3.Триггер таблицы для хэша заполнит таблицу k-комбинаций хэшаТо же самое динамическим SQL:create_SH_fuzzy_search_indexEXEC dbo.create_SH_fuzzy_search_index
    @schema_name            = 'dbo',
    @table_name             = 'customers', @table_id_field_name = 'id',
    --@table_name             = 'employees', @table_id_field_name = 'id',
    @table_mock_field_name  = 'Gender',
    @postfix                = 'full_name',
    @template               = 'ISNULL(first_name, '''') + ''%'' + ISNULL(patronomyc_name, '''') + ''%'' + ISNULL(last_name, '''')',
    @delimiter              = '%',
                            
    @h_table                = '',
    @hc_name                = '',
    @hc_table               = '',
    @h_table_join           = '',
    @hc_table_join          = '',
    @hc_table_case_col      = '',
    @hc_table_case_col_name = '',
    @row_size               = NULL,
                            
    @h_schema_name          = 'ix',
    @codepage               = '65001',
    @n                      = '1',
    @hashSize               = '32',
    @hashChunkSize          = '8',
    @kCombCount             = '2',
    @nGramHashModes         = '0',
    @salt_filter            = '0',
                            
    @is_del                 = 1,
    @top                    = 999999,
    @DEBUG                  = 0
create_SH_fuzzy_search_joinСоздаёт полноценный связочный индекс между двумя таблицами и процедуры, функции для работы с ним. Возвращаясь к нашей задаче:Запускает create_SH_fuzzy_search_index для customersЗапускает create_SH_fuzzy_search_index для employeesСоздаёт основную TVF, в которой хранится весь алгоритм поиска[ix].[customers_full_name-employees_full_name_H_1gram_x32_C_x8_K_2/4]/*
Generated in create_SH_fuzzy_search_join
-- usage
SELECT * FROM [ix].[customers_full_name-employees_full_name_H_1gram_x32_C_x8_K_2/4](1, 1) AS SH_search
*/
ALTER FUNCTION [ix].[customers_full_name-employees_full_name_H_1gram_x32_C_x8_K_2/4]
(
    @col_num    int = 1,
    @only_fuzzy int = 1
)
RETURNS table AS RETURN
(
 	--DECLARE @col_num int = 1, @only_fuzzy int = 1
    WITH
    residual_chunks AS
    (
        SELECT hc1.row_num AS rn1,
               hc2.row_num AS rn2
        FROM       [ix].[customers_full_name_H_1gram_x32_C_x8_K_2/4] AS hc1
        INNER JOIN [ix].[employees_full_name_H_1gram_x32_C_x8_K_2/4] AS hc2 ON (@col_num = 1 AND hc1.classic = hc2.classic)
    ),
    residual_ham_dist AS
    (
        SELECT DISTINCT
               rn1, rn2
        FROM             residual_chunks AS residual
        INNER JOIN [ix].[customers_full_name_H_1gram_x32] AS h1 ON residual.rn1 = h1.row_num
        INNER JOIN [ix].[employees_full_name_H_1gram_x32] AS h2 ON residual.rn2 = h2.row_num
        WHERE (@col_num = 1 AND dbo.HammingDistanceX32(h1.classic, h2.classic, 2) <= 2)
    ),
    residual_lev_dist AS -- query optimizer leaves this CTE for last, because it's necessary to JOIN the templates, which is what we want
    (
        SELECT residual.rn1, residual.rn2, t1.templ1, t2.templ2
        FROM       residual_ham_dist AS residual
        INNER JOIN (SELECT id AS rn1, ISNULL(first_name, '') + '%' + ISNULL(patronomyc_name, '') + '%' + ISNULL(last_name, '') AS templ1 FROM dbo.customers) AS t1 ON t1.rn1 = residual.rn1
        INNER JOIN (SELECT id AS rn2, ISNULL(first_name, '') + '%' + ISNULL(patronomyc_name, '') + '%' + ISNULL(last_name, '') AS templ2 FROM dbo.employees) AS t2 ON t2.rn2 = residual.rn2
        WHERE (@only_fuzzy = 0 AND dbo.LevenshteinDistanceString(t1.templ1, t2.templ2) <= 1)
           OR (@only_fuzzy = 1 AND dbo.LevenshteinDistanceString(t1.templ1, t2.templ2)  = 1)
    )
    SELECT * FROM residual_lev_dist
)

Создаёт вспомогательную процедуру [ix].[customers_full_name-employees_full_name_H_1gram_x32_C_x8_K_2/4(filter)] для удобной работы с индексом, позволяет join'ить другие таблицы и навешивать предикатыСоздаёт вспомогательную процедуру [ix].[customers_full_name-employees_full_name_H_1gram_x32_C_x8_K_2/4(index_size)] для анализа размера индексаСоздаёт вспомогательную процедуру [ix].[customers_full_name-employees_full_name_H_1gram_x32_C_x8_K_2/4(stat) для анализа селективности и заполненности хэшаТо же самое динамическим SQLcreate_SH_fuzzy_search_joinEXEC dbo.create_SH_fuzzy_search_join
    @schema_name_1           = 'dbo',
    @table_name_1            = 'customers', 
    @table_id_field_name_1   = 'id',
    @table_mock_field_name_1 = 'Gender',
    @postfix_1               = 'full_name',
    @template_1              = 'ISNULL(first_name, '''') + ''%'' + ISNULL(patronomyc_name, '''') + ''%'' + ISNULL(last_name, '''')',
    @delimiter_1             = '%',

    @schema_name_2           = 'dbo',
    @table_name_2            = 'employees', 
    @table_id_field_name_2   = 'id',
    @table_mock_field_name_2 = 'Gender',
    @postfix_2               = 'full_name',
    @template_2              = 'ISNULL(first_name, '''') + ''%'' + ISNULL(patronomyc_name, '''') + ''%'' + ISNULL(last_name, '''')',
    @delimiter_2             = '%',

    @h_schema_name           = 'ix',
    @codepage                = '65001',
    @n                       = '1',
    @hashSize                = '32',
    @hashChunkSize           = '8',
    @kCombCount              = '2',
    @nGramHashModes          = '0',
    @salt_filter             = '0',
    @lev_dist                = '1',
                 
    @is_del                  = 0,
    @top                     = 999999,
    @DEBUG                   = 0
ТестированиеКак пройти по моим стопам описано в github.com/VGoren/SHFuzzySearch/README.md. На моей машине с Intel Core i3 7gen Windows 11 x64 все тесты отрабатывают примерно за 1 час. Если у вас железо помощнее, то можно увеличить переменные @top_stat(для анализа индекса) и @top_srch(для замера производительности индекса). @top_stat меньше, т.к. вспомогательная аналитическая процедура (с постфиксом stat) достаточно затратная(не использует многопоток), в то же время данные однородны - увеличение выборки не влияет на аналитические показатели индекса.Итак, если всё сделали верно, то получите следующий результат:РезультатыОсновные поля таблицы результатов Поле                 описание                                                                                                   rn                   порядковый номер теста                                                                                     hash_name            название хэша                                                                                              salt_name            название соли                                                                                              lev_dist             расстояние Левенштейна                                                                                     data(KB)             размер данных индексных таблиц без учёта индекса(индекс весит гораздо меньше и его размер пропорционален)  data_calculated(KB)  расчётный размер данных индексных таблиц без учёта индекса                                                 time_create          время создания индекса                                                                                     combs                количество комбинаций при тестовом поиске                                                                  found                количество найденных совпадений                                                                            time_srch            время поиска                                                                                               stat_combs           количество выборочных комбинаций для анализа                                                               residual_chunks      количество комбинаций после 1, 2, 3-го этапа алгоритма  residual_chunks_%    в процентном выражении                                                                                     residual_ham_dist    количество комбинаций после 4-го этапа алгоритма  residual_ham_dist_%  в процентном выражении                                                                                     residual_lev_dist    количество комбинаций после 5-го этапа алгоритма  residual_lev_dist_%  в процентном выражении                                                                                     med_fullness         медианна заполненности хэша                                                                                med_fullness_%       в процентном выражении                                                                                     avg_fullness         среднее арифметическое заполненности хэша                                                                  avg_fullness_%       в процентном выражении                                                                                    Проанализируем результаты на примере выборки 5000 customers с 5000 employees:Анализ основных солейЕсли требуется реализовать нечёткий поиск БЕЗ резистивности к перестановке слов, то:salt_i_word - показывал себя наилучшим образом2gram + salt_i_word несплошной(2/4) - можно использовать в качестве беглого поискаЕсли требуется реализовать нечёткий поиск С резистивностью к перестановке слов, то salt_i_word использовать нельзя, поэтому практически все соли могут найти своё применение:salt_cnt_per_word - беглый поискsalt_cnt - более беглый поиск2gram несплошной(2/4) - наиболее беглый поиск2gram сплошной(4/8) - отрабатывает лучше classic'а, но весит большеДвойной хэш classic_1_2 везде проигрывает в производительности, хотя его селективность(residual_chunks_%)  слегка выше, чем у classic'а. Он теряет информацию о буквах с 3, 4, 5... повторениями. Поиск по тройному, четверному... хэшу потребует дополнительных intersect'ов, что повлечёт за собой увеличение операционной стоимости.У беглых поисков уменьшение селективности(residual_chunks_%) - не всегда обозначает   снижение истинной селективности, это может быть связано с уменьшением уязвимости к ложноотрицательным результатам - просто поиск становится более тщательным. Особенности анализа беглых поисковНа малых размерах индекса (размер хэша/количество строк в исходной таблице) прослеживается, что предельное увеличение размера хэша(hash_size) меньше предельного увеличения размера данных индексных таблиц(data(KB)) - SQLServer резервирует минимальное место под хранение метаданных, таких как информация о таблицах, столбцах, индексах и ограничениях Кривая размера индекса от размера хэшаРасчётный размер данных индексных таблиц data_calculated(KB) меньше, чем data(KB) - SQLServer оставляет свободные ""страницы"" с определённым fill-factor'ом таблицы (не путать с fill-factor'ом индекса) в файле данных для оптимизации операций с таблицей.Кривая скорости поиска от размера хэшаГрафик зависимости размера хэша(hash_size) от фактического времени поиска(time_srch) представляет из себя кривую параболического типа, на неё с двух сторон влияют следующие основные негативные факторы:При уменьшении размера хэша:Поиск по переполненному хэшу сопровождается множеством коллизионных join'ов переполненных chunk'овВероятность коллизии разных вводных внутри хэша - 1/hash_size(одна и та же буква может занять один и тот же бит). Чем сильнее селекивность(residual_chunks_%) хэша, тем губительнее для него этот фактор, поэтому максимальная скорость classic'а раскрывается на x512, а salt_i_word'а - на x1024.При увеличении размера хэша:Увеличение размера хэша, очевидно, увеличивает операционную стоимость join'ов. На слишком малых размерах хэшей проявляется слабо, потому что как SQLServer в частности, так и .NET в целом ""под капотом"" зачастую приводят значения к бóльшему типу данных - в конце концов, в современной 64-битной ОС процессор обрабатывает 64 бита за один такт.Поиск по слишком недозаполненному хэшу сопровождается множеством коллизионных join'ов вообще пустых chunk'ов. Проявляется на слишком недозаполненных хэшах.Кривая смещена по горизонтали влево. Влияние негативных факторов при уменьшении размера хэша усиливается сильнее, чем у негативных факторов при увеличении размера хэша - недозаполненный хэш лучше переполненного.Помимо основных факторов, на графике не отображены, но продолжают воздействовать дополнительные факторы: величина шаблона, уникальность данных, лингвистический аспект, количество букв в алфавите, рандом и др. Поэтому не стоит удивляться, что хэш x128 выбивается из общего ряда в худшую сторону. Возможно, на другом наборе данных он отработал бы лучше.Тестирование изменения размера текста не проводилось, но очевидно, что с его увеличением при заполнении сигнатурного хэша, мы неизбежно упрёмся в количество уникальных символов в алфавите, а при использовании солей - в статистическое сглаживание. В этом случае остается лишь одно - за вводные брать большие n-граммы, но они пропорционально увеличивают допуск ошибок в хэше. Для очень больших текстов этот поиск - не лучший выборИтого, увеличивать размера хэша(hash_size) стоит до тех пор, пока:Вас устраивает размер индексаНе перестанет увеличиваться селективность(уменьшаться residual_chunks_%)Не перестанет уменьшаться фактическое время поиска(time_srch)Да, инструмент узкоспециализированный... Надеюсь, кому-то пригодится. Спасибо за внимание!Теги:нечёткое сравнение строкрасстояние хэммингарасстояние левенштейнаhengineхэширование по сигнатуреsqlинтеграция стороннего кода в SQLmssqlsqlclrc#.netХабы:SQL.NETC#Microsoft SQL ServerАлгоритмы",265,0,0,23 мин,https://habr.com/ru/articles/965934/,43272,4656,5
GFS2 — файловая система для новой виртуализации: наш опыт интеграции в SpaceVM,SpaceVM,2025-11-13T08:00:18.000Z,"['Блог компании Space', 'Виртуализация *', 'Хранение данных *']","SpaceVM 3 часа назадGFS2 — файловая система для новой виртуализации: наш опыт интеграции в SpaceVMУровень сложностиСреднийВремя на прочтение13 минКоличество просмотров259Блог компании SpaceВиртуализация * Хранение данных * ТуториалПривет, Хабр! Меня зовут Сергей Алексанков, я технический директор Space. В этой статье расскажу о нашем опыте внедрения файловой системы GFS2 в платформу виртуализации SpaceVM.Облачные среды, отказоустойчивые кластеры и платформы виртуализации требуют от хранилищ не только надежности, но и поддержки одновременного доступа. В этих условиях традиционные файловые системы (EXT4, NTFS, XFS и др.) оказываются недостаточными — они не рассчитаны на работу с общими блочными устройствами между несколькими узлами. Одним из решений может стать кластерная файловая система, и одной из самых зрелых в этом классе является GFS2 (Global File System 2). Современные ИТ-инфраструктуры часто строятся вокруг виртуализации и облаков, где несколько серверов одновременно обращаются к одним и тем же данным. В таких системах ключевым становится не просто объем или скорость хранилища, а способ доступа к данным — общий или локальный, файловый или блочный. От того, как именно организовано взаимодействие с хранилищем, зависит архитектура всего решения: от производительности виртуальных машин до отказоустойчивости кластера.Локальные хранилища привычны для одиночных серверов: диск или массив принадлежит конкретному узлу, который управляет им напрямую. Общие (shared) хранилища, напротив, предоставляют единое пространство данных для нескольких серверов. Именно они лежат в основе высокодоступных кластеров и виртуализационных платформ, где важно, чтобы виртуальные машины могли мигрировать между узлами без потери доступа к своим дискам.Но общий доступ — это не только вопрос архитектуры, но и способа взаимодействия с данными. Файловые протоколы (NFS, SMB и др.) дают возможность работать с файлами на уровне операционной системы, но вносят дополнительные задержки и ограничения. Блочные протоколы (iSCSI, Fibre Channel) предоставляют более низкоуровневый доступ — сервер видит удаленное устройство как локальный диск. Однако при этом возникает другая проблема: как синхронизировать работу нескольких узлов с одним и тем же блочным устройством, не разрушив файловую систему?Ответ на этот вызов дают кластерные файловые системы, специально разработанные для совместного блочного доступа. Одна из самых зрелых и функциональных среди них — GFS2 (Global File System 2). В нашем опыте ее интеграция в собственный продукт - платформу виртуализации SpaceVM - позволила приблизиться к созданию устойчивой, масштабируемой и по-настоящему отказоустойчивой среды.SpaceVM — собственная разработка компании, платформа виртуализации на базе гипервизора KVM. Своего рода аналог vSphere от VMware, адаптированный под отечественные реалии и высокую степень автоматизации, это программный комплекс для управления вычислительными кластерами, автоматизации развертывания виртуальных машин и балансировки ресурсов между узлами. В его основе — идея унифицированного управления инфраструктурой: от гипервизора до сетевых и дисковых подсистем, с акцентом на прозрачность процессов и возможность интеграции с существующими ИТ-ландшафтами.С использованием GFS2 достигается эффект, сопоставимый по удобству и стабильности с использованием VMFS в продуктах VMware — с открытым исходным кодом и возможностью глубокой адаптации под нужды отечественных заказчиков.В архитектуре платформы стояла задача обеспечить общий доступ к блочному хранилищу между узлами кластера — без потери целостности данных и с возможностью одновременной работы виртуальных машин. При этом многие заказчики ожидали получить функциональность, сопоставимую с VMFS, используемой в продуктах VMware. Эти два требования сошлись в одной точке: для реализации такой модели доступа мы выбрали GFS2 — кластерную файловую систему, по принципам работы близкую к VMFS, но основанную на открытом коде и допускающую глубокую адаптацию под особенности отечественной инфраструктуры.GFS2: преимущества архитектуры и механизма блокировокGFS2 — это POSIX-совместимая кластерная файловая система, разработанная для работы с общими блочными устройствами, подключенными по Fibre Channel или iSCSI. Ее ключевая особенность — координация доступа к метаданным и содержимому файлов при помощи распределенного менеджера блокировок DLM (Distributed Lock Manager). Это позволяет гарантировать целостность данных даже при одновременном доступе с нескольких узлов. В отличие от NFS или SMB, где блокировки файлов координируются через сеть, GFS2 использует механизм локальных блокировок. Это принципиальное отличие: при сетевых файловых системах каждая операция блокировки требует удаленного вызова — будь то RPC-запрос или SMB-пакет — и ожидания ответа от сервера. Такие сетевые транзакции неизбежно добавляют задержку, особенно при высокой нагрузке или нестабильных сетевых условиях.В GFS2 же блокировки реализованы на уровне узлов кластера с использованием локальных ресурсов ОС и специализированных сервисов. Это значит, что большинство операций синхронизации выполняется без сетевых вызовов, напрямую внутри ядра или через быстрые механизмы обмена между узлами. Благодаря этому GFS2 обеспечивает более предсказуемое время отклика и лучшую масштабируемость при росте количества клиентов, чем файловые протоколы NFS или SMB.По сравнению с прямым пробросом блочных устройств в виртуальные машины, GFS2 предлагает более безопасный и управляемый способ совместного доступа к данным, не жертвуя скоростью и устойчивостью файловой системы.GFS2 демонстрирует сбалансированный и технологически обоснованный подход к организации доступа к общим данным, выгодно отличаясь как от сетевых решений вроде NFS или SMB, так и от схем прямого подключения блочных устройств без кластеризации.В сетевых файловых системах вся работа с данными происходит через удаленный сервер — каждая операция чтения, записи или блокировки требует сетевого запроса и подтверждения. Это упрощает администрирование, но создает точку отказа и ограничивает масштабирование: при росте нагрузки сервер становится узким местом, а задержки на уровне сети напрямую влияют на производительность.В противоположность этому, при прямом пробросе блочного устройства (или подход называемый SharedLVM) в несколько узлов вся логика управления данными перекладывается на хосты. Такой подход обеспечивает высокую скорость, но лишен механизмов согласования и защиты целостности: две машины могут записать разные данные в один и тот же блок, разрушив файловую систему.GFS2 решает обе проблемы одновременно. Она обеспечивает одновременный блочный доступ к устройству, но при этом использует встроенные кластерные механизмы — журналирование, распределенный менеджер блокировок (DLM) и систему метаданных, общую для всех узлов. За счет этого данные остаются согласованными, а операции синхронизации происходят быстрее, чем в сетевых файловых системах, поскольку выполняются на уровне ядра и не требуют посредничества сервера. Таким образом, GFS2 сочетает надежность и консистентность сетевых решений с низкими задержками и эффективностью блочного доступа.Второе важное преимущество — масштабируемость. Архитектура GFS2 допускает одновременный доступ к файловой системе с большого числа узлов, не требуя специальных клиентских или серверных реализаций. Это делает ее пригодной для использования как в компактных конфигурациях с 2–3 серверами, так и в полноценных кластерах с десятками узлов. При этом поддержка iSCSI и Fibre Channel дает гибкость в выборе СХД и не требует полной перестройки инфраструктуры. Третье — отказоустойчивость. В отличие от решений, где потеря одного узла может повлечь за собой повреждение данных или зависание всей файловой системы, GFS2 умеет корректно обрабатывать сбои. Механизмы fencing и quorum позволяют изолировать некорректно работающий узел, предотвращая split-brain и обеспечивая консистентность хранилища. Это особенно важно в условиях непрерывной работы платформ виртуализации, где потеря доступности даже части пула данных может повлечь каскадный отказ сервисов.Наконец, GFS2 упрощает администрирование за счет единого пространства имен и поддержки различных форматов данных. Это позволяет централизованно управлять пулами хранения и использовать привычные средства резервного копирования, миграции и диагностики. Для конечного пользователя это выражается в предсказуемом поведении системы и возможности разворачивать кластерные решения без глубокого погружения в особенности конкретных СХД или драйверов.На фоне альтернатив — GlusterFS, CEPH, Lustre — GFS2 занимает уникальное положение: это именно кластерная файловая система, работающая поверх одного общего устройства хранения, а не распределенная система с репликацией. Что делает ее особенно актуальной для сценариев, где важна экономия места, контроль над изоляцией данных и высокая предсказуемость поведения I/O.Для чего мы используем GFS2 в SpaceVMОдной из ключевых архитектурных задач в SpaceVM стало обеспечение полноценного доступа к общему хранилищу с возможностью запуска и миграции виртуальных машин на любых узлах кластера. Без использования внешней кластерной файловой системы это невозможно реализовать корректно. В виртуализированной инфраструктуре, где диски ВМ хранятся на сетевых LUN, только кластерная файловая система обеспечивает безопасный параллельный доступ с нескольких узлов, защиту от повреждения данных и поддержание высокой доступности. Именно в этом контексте в архитектуру SpaceVM была интегрирована GFS2 как штатный компонент хранилищ виртуальных машин.Благодаря GFS2, платформа получает следующие возможности, критически важные для промышленного использования:Хранение образов ВМ в виде файлов (формата qcow2) на общем устройстве, доступном всем серверам одновременно;Реализация высокой доступности (HA) за счет возможности мгновенного запуска виртуальной машины на любом из узлов без предварительной миграции её диска;Поддержка динамического перераспределения ресурсов (DRS), включая live migration, без необходимости вручную управлять блочными устройствами;Использование моментальных снимков, клонов и тонких дисков, с одновременной защитой от потерь данных при overcommit-сценариях — благодаря механизмам блокировок GFS2;Выполнение требований безопасности, предъявляемых заказчиками: например, возможность использовать атрибуты безопасности на уровне файлового слоя, чего невозможно достичь при прямом пробросе блочных устройств в ВМ.GFS2 в SpaceVM — не просто еще один способ монтировать хранилище, а полноценный архитектурный уровень, обеспечивающий устойчивость, управляемость и безопасность всей платформы.Однако простая интеграция GFS2 в SpaceVM оказалась невозможной. Нужно было добиться не только корректной работы файловой системы, но и органичной интеграции в архитектуру SpaceVM, где свои требования к кластерному транспорту, управлению ограждением узлов и мониторингу.Архитектура и технические сложностиФайловая система GFS2 не существует в изоляции — она требует работы в составе кластера и взаимодействует с рядом системных компонентов, формирующих так называемый кластерный транспорт. В этой архитектуре важны не только сама файловая система, но и сопутствующий ИТ-ландшафт, обеспечивающий согласованность операций, отказоустойчивость и синхронизацию между узлами.В первую очередь, GFS2 включает в себя менеджер DLM, который отвечает за координацию доступа к метаданным и содержимому файлов. Чтобы избежать ситуаций типа split-brain и гарантировать консистентность, применяется механизм ограждения (fencing), реализуемый через SBD (Storage-Based Death), чаще всего с использованием аппаратного watchdog-интерфейса IPMI. Файловая система GFS2 не работает автономно — она является частью кластерной инфраструктуры и требует взаимодействия с рядом системных сервисов, которые обеспечивают согласованность доступа и защиту данных. В отличие от обычных файловых систем, где единственный узел управляет диском, в кластере одновременно несколько машин читают и записывают данные на одно и то же блочное устройство. Это создает типичные распределенные проблемы — от гонок за блокировки до рассинхронизации метаданных при сбоях узлов.Чтобы избежать подобных ситуаций, GFS2 использует DLM. Он координирует доступ к метаданным и содержимому файлов, гарантируя, что ни один узел не изменит данные, пока другой с ними работает. Механизм блокировок распределенный, но выполняется внутри кластера, без участия центрального сервера, что снижает задержки и устраняет единую точку отказа.Однако даже с DLM остаются риски, связанные с частичными сбоями — например, когда узел теряет связь с сетью, но продолжает считать себя активным. Чтобы предотвратить разрушение данных в таких сценариях, применяется механизм fencing — изоляции или «отключения» проблемного узла. В GFS2 это реализуется через SBD (Storage-Based Death), который хранит управляющие метки на общем хранилище и при необходимости инициирует аппаратный перезапуск узла через интерфейс IPMI или watchdog. Таким образом, система сохраняет консистентность даже в условиях сетевых сбоев и частичных отказов, что критически важно для кластерной файловой системы.Кластерный транспорт GFS2 опирается на стек Corosync — это системный уровень, обеспечивающий коммуникацию между узлами и согласование их состояний. Важной частью надежной работы всей системы является синхронизация времени на всех узлах, обеспечиваемая через NTP: даже небольшие расхождения могут привести к рассогласованию в блокировках или ложным срабатываниям watchdog-механизма.Кроме того, для подключения LUN в инфраструктуре используются утилиты multipath-tools (в случае Fibre Channel) и open-iscsi (для iSCSI). Они обеспечивают корректное определение, маршрутизацию и управление путями к блочным устройствам, поверх которых и разворачивается файловая система GFS2.GFS2 — целостная кластерная подсистема, в которой управление доступом, синхронизацией, диагностикой и восстановлением после сбоев вынесено на уровень кластера. К системе/кластеру предъявляется ряд требований: строгое время синхронизации между узлами, устойчивость к потере сетевого трафика и возможность автоматического fencing'а при ошибках. Любые отклонения ведут к перезагрузкам узлов или развалу кластера.Трудности при развертывании GFS2: от теории к полевым реалиямХотя GFS2 — зрелая и мощная технология, ее внедрение в реальной инфраструктуре связано с рядом инженерных сложностей. Эти проблемы не всегда очевидны на этапе проектирования, но проявляются в момент масштабирования, нагрузки или интеграции в существующую платформу. Наш опыт развертывания GFS2 в составе SpaceVM показал: надежная работа кластерной файловой системы требует учета множества низкоуровневых факторов.Один из критических аспектов — синхронизация времени между узлами. GFS2 использует DLM и SBD, которые чувствительны даже к незначительным расхождениям во времени. Практика показала: если разница между узлами превышает 60 секунд, возможны некорректные решения по кворуму или ошибочные fencing-сценарии. Поэтому требуется жесткая настройка NTP-инфраструктуры с контролем точности синхронизации вплоть до миллисекунд.Следующая проблема — сетевые коллизии. При использовании iSCSI поверх общей инфраструктуры наблюдались случаи, когда трафик от виртуальных машин перекрывал каналы кластерного транспорта. Это приводило к задержкам, потере пакетов и, как следствие, рассинхронизации между узлами, развалу кворума и перезагрузкам. Особенно остро это проявлялось при объединении сетевых интерфейсов по LACP: реализация агрегации каналов у разных производителей оборудования иногда конфликтовала с работой iSCSI, вызывая нестабильные и трудноотлавливаемые ошибки. Мы отказались от LACP в пользу Active-Backup-режима, обеспечив тем самым предсказуемую работу с минимальной зависимостью от поведения сетевого оборудования.Отдельного внимания требует механизм ограждения через аппаратный watchdog. В нашем случае это IPMI-интерфейс, который должен реагировать на команды от SBD каждые 5 секунд. Однако в ряде инсталляций IPMI не успевал обработать запросы вовремя — из-за параллельных обращений от других сервисов или под нагрузкой. Это приводило к ложным fencing-сценариям: узел перезагружался без реальной причины. Решение — настройка возможности изменения таймаута watchdog’а и тщательное тестирование поведения IPMI на каждом типе оборудования.Также важно отметить трудности, возникающие при блокировке монтирования LUN. В случае некорректного завершения работы или проблем с доступом к СХД, файловая система могла зависать в состоянии ожидания, блокируя операции на уровне ядра. Требовались либо перезагрузка узла, либо использование низкоуровневых утилит для разблокировки ресурса. Подобные случаи невозможно игнорировать в продуктивной системе, и мы встроили в SpaceVM механизмы предиктивной диагностики, позволяющие заранее идентифицировать потенциальные блокировки по косвенным признакам.Интеграция GFS2 в платформу виртуализацииИнтеграция GFS2 в платформу виртуализации SpaceVM потребовала глубокого осмысления архитектуры кластерного транспорта и адаптации логики GFS2 под централизованную модель управления. В отличие от классического использования GFS2 в кластерах с ручной настройкой, здесь требовалось встроить файловую систему в оркестратор, который сам управляет вычислительными узлами, хранилищами и службами мониторинга через API и веб-интерфейс.Одна из ключевых проблем заключалась в несовместимости базовой логики GFS2 с концепцией SpaceVM. GFS2 ставит во главу угла сохранность данных: при любых ошибках, нарушениях кворума или сбоях с доступом к хранилищу система инициирует ограждение узла, то есть его принудительную перезагрузку. Напротив, SpaceVM ориентирован на непрерывную доступность ВМ и динамическую работу с узлами — даже при частичных деградациях инфраструктуры. В результате потребовалось реализовать механизм точной настройки поведения GFS2 через интерфейс платформы, чтобы у администратора была возможность балансировать между отказоустойчивостью хранения и живучестью вычислительного пула.Также было необходимо централизовать управление кластерным транспортом. В классическом варианте администратор вручную настраивает corosync, DLM, SBD, конфигурирует кольца, задает пороги кворума и поведение watchdog. В SpaceVM же вся эта конфигурация задается через API и визуальный мастер (wizard) создания GFS2-пула. Он позволяет в одном окне:выбрать диски,указать тип монтирования,настроить кластерный транспорт и fencing,развернуть файловую систему.Эта автоматизация особенно важна, поскольку GFS2 имеет высокий порог входа в плане требований к администратору. Ручная настройка — сложна и не масштабируется. Внедрение через интерфейс SpaceVM снимает барьер для широкого использования технологии.Мы внедрили централизованную валидацию настроек, автоматическое создание кластерного транспорта, подключение или отключение ограждений узлов, а также поддержку резервных сетей на базе протокола SCTP — они выбираются из UI и позволяют без прерывания работы переключаться между каналами связи.На уровне гипервизора также произошла серьезная интеграция. Контроллер SpaceVM передает вычислительным узлам команды через GRPC, синхронизируя настройки кластера, хранилищ и дисков. Все компоненты — от планировщика задач и очередей до сервисов синхронизации — взаимодействуют через собственную распределенную архитектуру. В этом окружении GFS2 стала частью общей системы: она управляется не вручную, а автоматически, через механизмы модулей Puppet, SSH-контроллеров и специализированных микросервисов.Особое внимание мы уделили типам монтирования и поведению ограждений. В GFS2 предусмотрены два основных сценария fencing’а:При потере кворума кластерного транспорта (split-brain).При ошибках записи или потере связи с блочным хранилищем.Мы реализовали возможность включать или отключать каждый из этих типов независимо, а также контролировать режим монтирования LUN (например, errors=panic или debug). В результате администратор получает не «чёрный ящик», а управляемую систему, где последствия сбоев можно смоделировать и задать заранее.Также были предприняты меры по валидации некорректных состояний:перед созданием нового транспорта проверяются конфигурации всех оставшихся узлов;при попытке монтирования система автоматически выявляет заблокированные LUN и предотвращает зависание задачи;по умолчанию отключена устаревшая опция создания дисков с полным выделением пространства (full), вместо неё используется falloc — это снижает нагрузку на GFS2 и исключает ошибки при записи.Таким образом, мы не просто подключили GFS2 как файловую систему — мы встроили её в архитектуру платформы виртуализации, превратив в управляемый, безопасный и масштабируемый компонент. Получилась не просто интеграция, а полноценная унификация двух миров: надёжного хранения и гибкой оркестрации вычислений.Оптимизация производительностиОднако даже после корректной настройки GFS2 может демонстрировать нестабильную производительность. В процессе внедрения мы протестировали и включили ряд оптимизаций:BFQ-алгоритм планирования ввода-вывода, сглаживающий пики нагрузки между ВМ;Обязательное использование virtio и hyper-v оптимизаций для улучшения взаимодействия между хостом и гостевыми ОС;Отказ от метода выделения диска full в пользу falloc — это устраняет ошибки записи и уменьшает нагрузку на подсистему хранения.Итоги: GFS2 — зрелое решение с инженерной спецификойGFS2 — мощный инструмент, который требует глубокого понимания. Его сила — в контроле над данными, гибкости и отказоустойчивости. Чтобы получить все преимущества его использования нужно глубокое понимание принципов его работы, особенно если разворачивать его «сбоку», не связывая с платформой. Сложность GFS2 — это не недостаток, а плата за мощь. Осознавая это, разработчики SpaceVM провели кропотливую работу по ее комплексной интеграции в свою платформу. В результате, то, что в изоляции воспринималось как слабость (чувствительность к среде, сложность настройки), было устранено. Пользователь получает всю силу GFS2 — контроль, гибкость, отказоустойчивость — через доступный интерфейс, автоматизацию и диагностику SpaceVM.Мы добились того, чего ждали от VMFS в отечественном исполнении: общего хранилища, совместимого с кластерами, виртуальными машинами и требованиями безопасности. А главное — доказали, что даже сложные opensource-компоненты могут органично встраиваться в коммерческие платформы, если подойти к этому как инженеры.Теги:gfs2gfsвиртуализациявиртуализация серверовхранилищахранение данныхинфраструктураvmware vspherevmfsХабы:Блог компании SpaceВиртуализацияХранение данных",259,0,0,13 мин,https://habr.com/ru/companies/spacevm/articles/965388/,22523,2805,3
Оптимизация налогообложения в игровой индустрии: как снизить расходы и защитить ключевые активы,DaniilKadyrov,2025-11-13T05:14:56.000Z,['Финансы в IT'],"DaniilKadyrov 6 часов назадОптимизация налогообложения в игровой индустрии: как снизить расходы и защитить ключевые активыУровень сложностиПростойВремя на прочтение6 минКоличество просмотров91Финансы в ITОбзорСовременная игровая индустрия давно перестала быть исключительно сферой развлечений и превратилась в мощный сегмент мировой экономики. Сегодня цифровые активы — будь то скины, внутриигровая валюта или даже целые виртуальные миры — оцениваются в миллионы долларов. Показательные примеры: продажа планеты Calypso в Entropia Universe за 6 млн долларов или виртуального Амстердама в Second Life за 50 тыс. долларов. Эти сделки демонстрируют финансовый потенциал GameDev. Но вместе с доходами неизбежно появляются и налоговые обязательства. Как разработчикам в России и за рубежом выстроить грамотную стратегию налогообложения и обеспечить защиту активов? Рассмотрим ключевые подходы.Важно отметить, сам термин «оптимизация налогообложения» многие налоговые консультанты используют с осторожностью. В отличие от классической оптимизации расходов, здесь речь идёт не о сокращении обязательств, а о выборе наиболее подходящей модели ведения бизнеса, использовании предусмотренных законом льгот и специальных режимов. Однако, не имея более точного определения, будем использовать привычный термин «оптимизация».Налогообложение внутриигровых транзакций в РоссииВ российской юрисдикции для игровой индустрии не предусмотрено отдельного налога на виртуальные активы, поэтому компании подчиняются общим нормам Налогового кодекса РФ.Основные налоговые обязательства включают:налог на прибыль — 25%;налог на добавленную стоимость (НДС) — 20%;налог на имущество — до 2,2% (ставка зависит от региона);страховые взносы — около 30% от выплат в пользу физических лиц;НДФЛ — от 13% с доходов граждан.Любая реализация внутриигровых предметов, включая проекты по модели free-to-play, рассматривается как доход, облагаемый налогом на прибыль и, в ряде случаев, НДС. С правовой точки зрения такие транзакции квалифицируются как передача прав на использование «неактивированных данных и команд» по лицензионному соглашению.Эта позиция получила официальное подтверждение в письме ФНС России от 2017 года № СД-4-3/988@, где было закреплено, что при корректном оформлении подобные операции могут освобождаться от уплаты НДС. Для разработчиков это стало важным инструментом снижения налоговой нагрузки.Кейс Mail.ru: уроки из практикиВ 2015 году налоговые органы оспорили освобождение от НДС по операциям, связанным с продажей внутриигровых предметов в проектах Mail.ru Group (Warface, «Аллоды Онлайн»). Инспекция квалифицировала такие сделки не как передачу прав на программное обеспечение, а как оказание услуг по организации игрового процесса, что влекло обязанность уплачивать НДС.Суды поддержали позицию налоговиков, что создало неблагоприятный прецедент для разработчиков. Однако в 2017 году ситуация изменилась, в письме ФНС № СД-4-3/988@ было закреплено право рассматривать подобные операции именно как передачу прав на использование программного обеспечения. Это дало студиям возможность корректно оформлять сделки и существенно снижать налоговую нагрузку.Налоговые льготы для игровой индустрииРазработчики игр могут значительно снизить фискальную нагрузку, используя предусмотренные законом льготные режимы. Рассмотрим ключевые инструменты, доступные как в России, так и за её пределами.1. IT-аккредитация в РоссииСтатус аккредитованной IT-компании, подтверждаемый Минцифры РФ, предоставляет целый ряд преимуществ:налог на прибыль снижается до 5%;страховые взносы уменьшаются до 7,6%;передача прав на ПО из реестра российского ПО освобождается от НДС.Для получения аккредитации требуется, чтобы более 70% дохода компании приходилось на IT-деятельность.Пример: студия Astrum Entertainment, разработчик проекта BLACK RUSSIA.2. Режим «Сколково»Резиденты инновационного центра «Сколково» могут рассчитывать на ещё более заметные преимущества:налог на прибыль — 0%;НДС — освобождение;страховые взносы — 14%.Ограничения: льготы действуют в течение 10 лет и прекращают применяться при выручке свыше 1 млрд рублей или прибыли более 300 млн рублей. При грамотном комбинировании с IT-аккредитацией возможно снижение страховых взносов до 7,6% при нулевом налоге на прибыль.3. Упрощённая система налогообложения (УСН)Для небольших студий эффективным инструментом становится УСН:ставка 6% от дохода — без учёта расходов;ставка 15% от дохода за вычетом расходов — с возможностью учитывать траты на разработку и оборудование.УСН освобождает от НДС при выручке до 60 млн рублей. При превышении этого порога применяются льготные ставки:5% НДС при доходе до 250 млн рублей;7% НДС при доходе до 450 млн рублей.Ограничения:годовой доход — до 450 млн рублей;численность сотрудников — до 130 человек;остаточная стоимость основных средств — не выше 150 млн рублей.4. Международные инструменты: IP Box и налоговая отсрочкаМногие игровые компании регистрируют бизнес за рубежом, чтобы воспользоваться специализированными налоговыми режимами. Наибольшей популярностью пользуются Кипр, Эстония и ОАЭ.IP Box — режим снижения налоговой нагрузки на доходы от интеллектуальной собственности (ИС):Кипр: 80% прибыли от ИС исключается из налогооблагаемой базы;ОАЭ: ставка по прибыли от ИС — 0%;Казахстан: налоговая база уменьшается на 100%.Льгота зависит от коэффициента связи (nexus ratio), который отражает долю квалифицированных затрат (например, зарплат разработчиков) в общих расходах на создание продукта.Пример: в ОАЭ при nexus ratio 80% и прибыли $1 млн налог 0% применяется к $800 тыс., а оставшиеся $200 тыс. облагаются по ставке 9%.Отсрочка уплаты налога на прибыль действует в Эстонии и Грузии, налог платится только при распределении дивидендов. Это позволяет без потерь реинвестировать доходы в новые проекты, активы или объекты ИС, что особенно выгодно для холдингов и венчурных фондов.R&D-вычетыВ Чехии и Дании расходы на разработку ПО можно списывать по повышенной ставке (например, 200%). Это снижает налогооблагаемую базу.Пример: при выручке $1 млн и расходах на R&D $300 тыс. с вычетом 200% налогооблагаемая прибыль сокращается с $700 тыс. до $400 тыс. В Чехии подобные вычеты можно переносить на будущие периоды (до трёх лет), что особенно выгодно для стартапов без текущей прибыли.Защита и сопровождение активовДля компаний игровой индустрии нематериальные активы являются фундаментом бизнеса. Исходный код, графика, игровые механики, бренд и торговые марки — всё это требует не только технической проработки, но и надёжной правовой защиты.Ключевыми инструментами в этой сфере выступают:грамотно составленные пользовательские соглашения;прозрачные политики конфиденциальности, соответствующие требованиям международных платформ и регламентов (включая GDPR);регистрация прав на объекты интеллектуальной собственности.Без этих документов невозможно выйти на международный рынок, легально монетизировать продукт или привлечь инвестиции.Особое внимание необходимо уделять формулировкам, особенно в проектах с внутриигровыми покупками, подписками или возможностью вывода средств. Некорректные условия могут привести не только к блокировке приложения в App Store или Google Play, но и к риску признания игры азартной с последующими правовыми последствиями.На практике защита активов — это не разовое оформление документов, а непрерывный процесс, включающий аудит, регулярное обновление соглашений и мониторинг регуляторных требований в различных юрисдикциях. Только комплексный подход позволяет минимизировать риски штрафов, санкций и судебных разбирательств, сохраняя при этом контроль над ключевыми элементами продукта.Риски и практические рекомендацииНалоговые спорыОколо 20% конфликтов в IT-сфере связано с вопросами налогообложения роялти и проблемой двойного налогообложения. Снижение рисков достигается за счёт продуманного структурирования бизнеса — например, регистрации компании в юрисдикциях с режимом IP Box (Кипр, Нидерланды), что позволяет оптимизировать налогооблагаемую базу.Санкции со стороны платформНесоблюдение правил App Store или Google Play — например, публикация контента, не соответствующего возрастным ограничениям, — может привести к предупреждениям, удалению или даже полной блокировке приложения. Регулярная проверка документации, аудит пользовательских соглашений и контроль контента позволяют минимизировать эти угрозы.Внутренние конфликтыОколо 30% споров в GameDev связано с разногласиями между основателями или ключевыми сотрудниками. Чётко прописанные трудовые контракты, партнёрские соглашения и документы о распределении долей существенно снижают вероятность подобных конфликтов.Выбор юрисдикцииПравильный выбор страны регистрации играет решающую роль. Кипр, Эстония и Гонконг востребованы благодаря выгодным налоговым режимам и надёжной защите интеллектуальной собственности. При этом стоит избегать юрисдикций с высокой налоговой нагрузкой (Франция, Италия) или слабой правовой защитой прав на ИС (например, Украина).Комплексное внимание к этим аспектам позволяет не только снизить риски, но и создать устойчивую основу для долгосрочного развития игровой компании.ЗаключениеСовременная разработка игр — это не только креативные идеи и технологические решения, но и выстроенная правовая устойчивость, прозрачная налоговая структура и стратегическое планирование. Успешный проект требует не только качественного кода и проработанной механики, но и корректно оформленных прав на интеллектуальную собственность, продуманной налоговой модели и строгого соблюдения требований платформ и регуляторов.В российской практике разработчики могут использовать такие инструменты, как IT-аккредитация, статус резидента «Сколково» или УСН, чтобы сократить налоговую нагрузку. Международные механизмы — от IP Box и отсрочки налога на прибыль до R&D-вычетов — дают возможность масштабировать бизнес и защищать доходы на глобальном рынке. Однако все эти инструменты эффективны лишь при условии наличия комплексной юридической инфраструктуры.Без детально проработанных пользовательских соглашений, надёжной политики конфиденциальности и зарегистрированных прав на ключевые активы даже самая популярная игра остаётся уязвимой. Поэтому юридическое сопровождение — это не второстепенный элемент, а обязательная часть стратегии выхода на рынок и устойчивого развития любой GameDev-компании.Теги:оптимизация налогообложения gamedevналоги в игровой индустрииналоговые льготы для it-компанийналоговая оптимизация it-бизнесаХабы:Финансы в IT",91,0,0,6 мин,https://habr.com/ru/articles/965894/,10422,1287,1
Архитектурный выбор: Монолит против микросервисов без технического диплома,lukyan73,2025-11-13T09:59:44.000Z,"['Анализ и проектирование систем *', 'Микросервисы *', 'Управление продуктом *', 'Управление проектами *', 'Управление разработкой *']","lukyan73 1 час назадАрхитектурный выбор: Монолит против микросервисов без технического дипломаУровень сложностиПростойВремя на прочтение3 минКоличество просмотров167Анализ и проектирование систем * Микросервисы * Управление продуктом * Управление проектами * Управление разработкой * МнениеRecovery ModeКак нетехническому специалисту участвовать в принятии решений, от которых зависят бюджет, сроки и масштабируемость продуктаАрхитектурные решения — это фундамент цифрового продукта. Выбор между монолитной и микросервисной архитектурой определяет, насколько быстро вы сможете выпускать новые функции, как будет масштабироваться бизнес и какие команды вам потребуются. Это не чисто технический вопрос, а стратегический, напрямую влияющий на финансовые и операционные показатели.Многие нетехнические специалисты — продуктологи, менеджеры, основатели стартапов — чувствуют себя исключенными из этого разговора. Их задача — не писать код, а понимать бизнес-последствия выбора и говорить с разработчиками на понятном им языке. Вот практический фреймворк, который поможет участвовать в этих обсуждениях на равных.Базовые концепции: два подхода к архитектуреМонолит — единая, неделимая система. Все компоненты (база данных, серверная и клиентская логика) тесно связаны и развертываются как одно целоеМикросервисы — набор независимых сервисов, каждый из которых отвечает за конкретную бизнес-возможность и общается с другими через четко определенные интерфейсы (API)Три критерия для принятия решения на языке бизнесаВместо споров о технологиях сосредоточьтесь на факторах, которые понятны любому руководителю.1. Структура команды: Масштабируемость против оперативной скоростиОрганизация вашей команды напрямую определяет оптимальный архитектурный выбор.Монолит эффективен для небольших сплоченных команд. Разработчики работают с единой кодовой базой, что позволяет быстро вносить изменения и оперативно решать задачи. Отсутствие необходимости согласовывать форматы взаимодействия между независимыми сервисами ускоряет разработку на ранних этапах.Микросервисы становятся оправданы при наличии нескольких автономных команд, каждая из которых фокусируется на своей зоне ответственности. Эта модель позволяет командам разрабатывать, тестировать и развертывать свои сервисы независимо. Однако попытка разрабатывать микросервисную архитектуру силами одной небольшой команды ведет к резкому росту сложности и непропорциональным временным затратам.2. Стабильность требований: Гибкость против предсказуемостиВыбирайте монолит для продуктов с быстро меняющимися требованиями — стартапы, MVP, экспериментальные направления. Это позволяет быстро итерировать и перенаправлять ресурсы, не разрывая контракты между сервисами.Микросервисы эффективны для стабильных продуктов с четкими границами доменов. Когда функциональность модуля определена на месяцы вперед, его можно выделить в отдельный сервис. Частые кросс-сервисные изменения в микросервисной архитектуре требуют значительных координационных усилий.3. Толерантность к отказам: Простота против отказоустойчивостиВ монолите отказ одного модуля часто означает остановку всей системы. Это приемлемо на ранних стадиях, когда кратковременные простои не так критичны для бизнеса.Микросервисы обеспечивают изоляцию сбоев — если один сервис недоступен, остальные продолжают работать. За эту отказоустойчивость вы платите: мониторинг десятков сервисов и обеспечение их стабильного взаимодействия требуют значительных операционных ресурсов.Ключевой вывод для бизнесаПравило простое: начинайте с монолита, эволюционируйте к микросервисам через осознанный переход.Стартапы и новые продукты: Ваша главная валюта — скорость выхода на рынок и проверка гипотез. Монолит дает вам максимальную гибкость при минимальных операционных затратах.Растущие продукты: Когда команды начинают мешать друг другу в монолите, а границы сервисов стали четкими и стабильными — это сигнал к постепенному, обоснованному переходу на микросервисы.Самые дорогостоящие архитектурные ошибки происходят, когда компания пытается построить распределенную систему без соответствующих командных структур и процессов.P.S. Если вы хотите не просто понимать такие решения, а уверенно участвовать в архитектурных обсуждениях, задавать правильные вопросы и оценивать риски — в моей книге «Птичий язык: Как говорить на языке разработчиков, не написав ни строчки кода» я подробно разбираю логику IT-архитектуры, процессы разработки и модели сотрудничества. Это поможет вам говорить с техническими специалистами на одном языке и принимать взвешенные совместные решения.Теги:монолитархитектурамикросервисыХабы:Анализ и проектирование системМикросервисыУправление продуктомУправление проектамиУправление разработкой",167,0,0,3 мин,https://habr.com/ru/articles/966028/,4695,544,5
Как поменять улыбку без масштабного лечения?,docdeti_docmed,2025-11-13T10:33:45.000Z,"['Блог компании Сеть клиник docmed и docdent', 'Здоровье', 'Научно-популярное']","docdeti_docmed 42 минуты назадКак поменять улыбку без масштабного лечения?Время на прочтение1 минКоличество просмотров175Блог компании Сеть клиник docmed и docdentЗдоровьеНаучно-популярноеКейсБывает так, что улыбка не нравится, и хочется всё изменить, но... прямо сейчас нет возможности провести большое лечение. Но это не повод ходить грустить и не улыбаться. Как можно поменять улыбку рассказывает и показывает стоматолог-ортопед Мария СпивакДевушка обратилась с жалобами на внешний вид передних зубов: ей не нравилась и форма и их состояниеФото ""до""На осмотре мы определили ряд проблем: старые несостоятельные реставрациикариозные полостивыраженная стираемость передних зубовОбсудили с пациенткой план лечения и других зубов — с возможными удалениями, установкой имплантов и коронок.Но пока девушка не готова к масштабному лечению, решили начать с малого и заняться передними зубами, которые её беспокоят. Так бывает, и задача врача — услышать пациента и подобрать адекватные альтернативы, которые улучшат жизнь человека прямо сейчасЯ предложила промежуточный этап, который устроил пациентку, и мы воплотили план в жизньЧто сделали? удалили все старые реставрации с передних зубовпролечили кариозные полостивосстановили цвет и эстетику композитными винирамиФорму и цвет подбирали вместе с пациенткойВ будущем планируем провести большую работу со всеми зубами: с удалениями, имплантами и коронками. Композитные реставрации придётся менять, и пациентка к этому готова. Впереди тотальная реабилитация, но несколько лет красивой улыбки мы ""выиграли"", и сейчас девушка улыбается открытоПолучить красивую улыбку можно уже сейчас, не откладывая зубные проблемы ""на потом"". А над более сложными этапами планомерно работать вместе с врачом Теги:улыбказубвинирстоматологияХабы:Блог компании Сеть клиник docmed и docdentЗдоровьеНаучно-популярное",175,0,0,1 мин,https://habr.com/ru/companies/docmed_docdent/articles/965800/,1837,233,3
"Почему простые фичи — самые сложные: история о пет-проекте, Дженге и маржинальной торговле",impatient,2025-11-13T05:16:22.000Z,"['Java *', 'Программирование *', 'Финансы в IT']","impatient 6 часов назадПочему простые фичи — самые сложные: история о пет-проекте, Дженге и маржинальной торговлеУровень сложностиСреднийВремя на прочтение9 минКоличество просмотров538Java * Программирование * Финансы в ITИз песочницыПривет, Хабр! Меня зовут Иван, и сегодня я хочу поделиться историей о своём пет-проекте A-Zero. Истории про провалы традиционно интереснее историй об успехах, и моя как раз такая (почти). Довольно бодроначинавшийся проект чуть было не свёл меня с ума из‑за одной единственной фичи, «просочившейся» в MVP, и сейчас я расскажу, как я из этого выкарабкался и чему научился по дороге.Дисклеймер: в тексте присутствует некоторое количество терминов, относящихся к трейдингу. Для удобства не столь искушённого читателя большинство из них снабжены всплывающими подсказками с пояснениями.Мир, где всё простоВсё началось со слегка безумной идеи написать с нуля фреймворк для алгоритмического крипто-трейдинга в качестве сольного пет-проекта. Я понимал, что единственный шанс для начинающего Java-разработчика (меня) преуспеть в таком нелёгком деле — чётко следовать принципу итеративной сложности. Нужно было начать с чего-то совсем элементарного и очень маленькими порциями достраивать функционал — как будто играешь в Дженгу и боишься, что от каждой следующей палочки всё рухнет.Поначалу всё шло довольно бодро, и мы с проектом дожили до релиза 0.1.0 — он состоял из CLI утилиты для выгрузки исторических данных, плюс я успел прикрутить небольшой CI пайплайн. Вскоре у меня уже были готовы основные интерфейсы и базовая реализация движка для бэктестинга, который умел моделировать спотовые трейды. Казалось, что фундамент моей башни в Дженге заложен, и теперь осталось только докладывать на него палочки-фичи, а на горизонте уже замаячил следующий релиз с полноценной утилитой для бэктестинга — нужно было только реализовать логику описания стратегий и написать поверх всего этого CLI-обёртку.Стоит сказать, что слово ""базовая"" в применении к реализации движка тут не было скромностью — он действительно был безумно простым и использовал очень базовую логику:Один счёт (double balance).Только одна открытая позиция в один момент времени.Простая логика: купил — баланс уменьшился, продал — увеличился.И вот тут предыдущий успех, видимо, заставил меня расслабиться, и...Кроличья нораЯ решил, что такой релиз получится уж слишком скучным и примитивным. А вот если добавить в него всего одну «палочку» — шорт‑трейды... Тут, каюсь, сыграли роль сразу два фактора: во‑первых, отсутствие у меня чёткого плана по MVP, во‑вторых — немного замутнившиеся воспоминания из моего прошлого трейдерского опыта о том, как трейдинг, собственно, устроен. Поэтому я практически машинально добавил в модель стратегии возможность шортить активы, и только потом уже задумался, рассчитан ли на это мой движок — но обо всём по порядку.Изначально мне казалось, что добавление шорт‑трейдов — фича чисто номинальная, и на логику программы в целом не повлияет. Первым звоночком стало нарушение модели баланса (double balance). Дело в том, что изначально она была призвана играть двоякую роль: с одной стороны — отражать покупательную способность в ходе симуляции (то есть какие трейды мы можем себе позволить), с другой — показывать состояние нашего капитала, то есть сколько мы заработали/потеряли.Но при открытии шорта мы не тратим, а получаем средства — и, наоборот, теряем при закрытии. Так модель double balance моментально перестала работать. «Ничего, просто чуть‑чуть усложним модель!» — оптимистично подумал я и взял в руки следующую палочку Дженги: полноценный Map<String, Double> кошелёк, отслеживающий баланс (в т.ч. отрицательный) каждого имеющегося актива.Теперь я мог учитывать, что при открытии шорта для базовой валюты баланс уменьшается, а для валюты котировки — увеличивается. Также пришлось добавить движку два режима симуляции: маржинальная торговля и спотовая торговля, а ещё поддерживать в симуляции неограниченное количество открытых позиций.И вот тут я ощутил, что начинаю падать в кроличью нору маржинальной торговли. Теперь для реалистичной симуляции мне нужно было рассчитывать ещё и такие вещи как:Залог: Просто так взять актив в долг нельзя — биржа рассчитывает требуемый объём обеспечения заёма имеющимися у трейдера средствами. В современных крипто-биржах существует концепт ""объединённого торгового аккаунта"", для которых это обеспечение рассчитывается исходя из балансов всех активов на аккаунте. Биржи предоставляют некоторую документацию касательно алгоритма этого расчёта, которую мне пришлось изучить, а затем практически полностью переписывать логику исполнения ордеров.// Рассчитываем необходимую начальную маржу для новой позиции
BigDecimal imr = calculateInitialMarginRate();
BigDecimal newMarginRequired = positionValue.multiply(imr);
BigDecimal totalEquity = calculateTotalEquity(this.currentPrices);
BigDecimal existingMargin = calculateTotalInitialMargin();

// Проверяем, достаточно ли у трейдера общей эквити для открытия
if (totalEquity.subtract(existingMargin).compareTo(newMarginRequired) < 0) {
    log.warn(
        ""MARGIN CHECK FAILED: Cannot open {} position for {}. Required: {}, Available: {}"",
        direction, symbol, newMarginRequired, totalEquity.subtract(existingMargin));
    return;
}Поддерживающая маржа: Помимо расчёта обеспечения в момент заёма актива, постоянно проверяется, что общая стоимость активов трейдера не упала ниже уровня поддержания маржи (зависит от общего объёма заёмных активов; обычно равен определённой доле от изначального обеспечения при заёме). Нужно было добавить дополнительную логику на каждом цикле симуляции.// Обновляем актуальную информацию о ценах активов
context.updateCurrentPrices(currentPrices);

// С помощью хелперов проверяем, нужно ли запускать ликвидацию
if (config.getAccountMode() == AccountMode.MARGIN) {
    if (context.isMarginCallTriggered()) {
        context.liquidateAllPositions();
    }
}Принудительная ликвидация: Самая страшная и самая важная часть. Если баланс активов падает ниже уровня поддерживающей маржи (см. предыдущий пункт), происходит margin call — биржа начинает принудительно продавать активы трейдера, чтобы покрыть недостаток обеспечения. Это необходимо было реализовать, чтобы симуляция была ""честной"".Сложнее всего было, конечно, остановиться: можно было провести ещё неопределённое количество времени в попытках сделать симуляцию всё более и более реалистичной, но в какой-то момент я сказал себе ""стоп"". Во-первых, это нарушало бы принцип итеративной сложности. Во-вторых, очень сильно замедлило бы меня. В-третьих, не было особенно осмысленным: бэктестер призван служить первой ""дешёвой"" ступенью анализа, а следующий этап — демо-трейдинг, реализация которого у меня есть дальше в дорожной карте, — в любом случае решил бы проблему с неточной симуляцией. В итоге я уговорил себя сделать следующие упрощения:Явную формулу для расчёта объёма обеспечения заёма найти не удалось (точнее, формула из документации банально расходилась с тем, что я видел на самой бирже), поэтому в движке я использовал заведомо более «агрессивную» формулу — это значило, что движок позволит стратегии взять в долг чуть меньше, чем, возможно, позволила бы биржа (что безопасно).Вместо каскадной ликвидации (продажи активов в определённом биржей порядке) при принудительной ликвидации движок моделирует закрытие всех позиций — на мой взгляд, это простительная неточность, так как принудительная ликвидация сама по себе означает «фейл» стратегии, и моделировать реальные последствия не так критично для реализма.На руинах APIРазобравшись с тем, что фактически стало полным рефакторингом движка для бэктестинга, я обнаружил, что, помимо изменений в логике, теперь у меня полностью разрушились контракты API. Вот пара примеров:Пример 1: Эволюция TradingContext. Изначально это был крайне минималистичный интерфейс, описывающий взаимодействие стратегии с ""биржей"". В начале стало очевидно, что примитивные методы executeBuy/Sell плохо смотрятся в контексте нескольких режимов торговли (спот и маржинальная) — вместо них появился более абстрактный и семантичный submitOrder. После этого, во многом в процессе тестирования, стало понятно, что интерфейс слишком закрытый — нужен гораздо более широкой read-only доступ к состоянию аккаунта. Здесь помогла ментальная модель ""TradingContext — абстракция над веб-интерфейсом криптобиржи"". Так появились методы для получения состояния кошелька, общей стоимости активов на аккаунте и т.д.Пример 2: Эволюция Strategy и рождение MarketEvent. В сценарии, где стратегия взаимодействовала с несколькими активами одновременно, простой метод onCandle(Candle c, ...) уже не работал — тип Candle (свеча) был намеренно сделан минималистичным и не давал контекста о том, по какому активу получена информация. Из этого родился новый тип MarketEvent — ""обёртка"" над свечой и символом актива, а интерфейс Strategy теперь содержал onMarketEvent(MarketEvent event, ...). Так стратегия получала всю нужную её внутренней логике информацию — а ещё это сделало интерфейс более гибким: при необходимости я мог бы расширить тип MarketEvent, не меняя контракты API.С одной стороны, можно с уверенностью сказать, что это были правильные и необходимые изменения. С другой — они происходили абсолютно не в том порядке, в котором я хотел бы их вносить. Вместо ""отлично, работает, давайте улучшать"" получилось ""оно сейчас развалится, если я ничего не сделаю"".TDD?Неожиданно для меня там, где в борьбе с потихоньку наступавшим в проекте хаосом паттерны проектирования мне уже не помогали, на помощь пришли тесты — но не совсем в привычном их понимании.Из-за внезапного бурного разрастания бизнес-логики стало сложно держать в голове не только то, как именно она работает, но даже то, что она вообще говоря должна делать. И здесь тесты оказались прекрасным инструментом — не для того, чтобы верифицировать поведение, а для того, чтобы его прояснять. Фактически, я пытался декларативно описывать желаемое поведение через тесты (почти как в Test-Driven Development), чтобы затем на падающих тестах смотреть, в чём именно ошибка — в бизнес-логике или в моих от неё ожиданиях.Например, при тестировании движка для бэктестинга неожиданно стал падать тест spot_shortAttempt_ShouldThrowException. Вместо исключения при попытке в режиме спот-торговли продать актив, которого нет на балансе аккаунта, система... Не делала ничего. Проверив, по какой ветке идёт бизнес-логика, я выяснил, что вместо того, чтобы обрабатывать такой ордер как шорт-трейд, движок воспринимал его как попытку продать актив в большем количестве, чем есть у трейдера — и просто игнорировала его, выводя предупреждающее сообщение.Поведение системы оказалось правильнее моего собственного понимания — там, где я ожидал, что невозможная операция приведёт к ошибке, движок просто корректно её игнорировал. В этот момент я понял, что тестами можно не просто ловить баги и отслеживать, где логика работает не так, как задумано — хорошо написанные тесты помогают выявить места, где логика изначально была задумана неправильно.Отдельным вызовом при тестировании стала дилемма ""инкапсуляция vs. тестируемость"". Поскольку многие компоненты были довольно сложными stateful объектами, тестировать их без верификации внутреннего состояния было практически бессмысленно — но как сделать внутреннее состояние доступным в тестах, не засоряя публичный API? Решением стали аккуратно подобранные package-private методы, создававшие специальное тестовое API с минимальной необходимой ""площадью покрытия"":// package-private метод для мониторинга завершённых трейдов в тестах
List<Trade> getExecutedTradesForTest() {
    return List.copyOf(this.executedTrades); // Возвращяем безопасную immutable копию
}Хэппи эндВ итоге, спустя пару недель рефакторинга и доработки, релиз 0.2.0 был готов. Помимо CLI-бэктестера и YAML формата для описания трейдинговых стратегий, в нём теперь было гораздо более надёжное, гибкое и близкое к реальности ядро в виде бэктест-движка и API-контрактов. Но самым ценным для меня, пожалуй, стали не фичи, а сам опыт, который я приобрёл в процессе разработки:Беспощадное ""M"" в MVP. Невероятно трудно в процессе написания кода не хвататься за каждую возможность что-нибудь ""улучшить"" и добавить в свою башню в Дженге ещё одну палочку. Но, как показал мой кейс, очень важно иметь дисциплину этого всё-таки не делать — иначе всю башню придётся бесконечно пересобирать заново. Правильным решением в моём случае было бы остановиться в MVP на реализации логики спотовой торговли, а потом итеративно усложнять уже функционирующий движок.Упрощай, прежде чем усложнять. В процессе добавления в движок логики маржинальной торговли в какой-то момент начало казаться, что каждая новая реализованная концепция тянет за собой ещё две нереализованных. Для продуктивной разработки гораздо ценнее иметь что-то простое и работающее, поэтому было важно ""провести черту"" в том, насколько точно я хочу симулировать реальность. Логику всегда можно усложнить впоследствии — по результатам тестов, которые покажут, где именно эти усложнения действительно необходимы. А для этого нужно сначала создать что-то, что уже можно будет тестировать.Тесты как инструмент прояснения, а не только проверки. Я не могу с чистой совестью назвать свой подход реальным TDD — всё-таки тесты писались уже после того, как была написана основная масса логики. И всё-таки в критический момент именно тесты как раз оказались таким островком предсказуемости и стабильности, благодаря которому проект не развалился. Можно сказать, что в ходе разработки у меня самопроизвольно зародился некий паттерн TDC — ""Test Driven Clarification"". И я уверен, что обязательно прибегну к этой практике в дальнейших этапах работы над моим проектом.Спасибо, что дочитали мою первую публикацию до конца :-) Буду рад услышать ваши мысли и критику в комментариях. Расскажите, какие «простые» фичи стопорили ваши проекты?Весь код ядра проекта A-Zero открыт и доступен на GitHub.Теги:трейдингпет-проектХабы:JavaПрограммированиеФинансы в IT",538,0,0,9 мин,https://habr.com/ru/articles/965896/,13957,1864,3
Go-to-Community вместо Go-to-Market,badcasedaily1,2025-11-12T13:12:31.000Z,"['Блог компании OTUS', 'Developer Relations *', 'Управление продуктом *']","badcasedaily1 22 часа назадGo-to-Community вместо Go-to-MarketУровень сложностиСреднийВремя на прочтение17 минКоличество просмотров181Блог компании OTUSDeveloper Relations * Управление продуктом * ОбзорПривет, Хабр! Сегодня поговорим про стратегию Go‑to‑Community вместо Go‑to‑Market. Звучит конечно круто, но суть простая: перестать видеть разработчиков только как лидов в воронке продаж и начать работать с ними как с сообществом на равных, с созданием ценности для всех. Go-to-Market vs Go-to-Community: в чем разница?Для начала небольшой ликбез. Go‑to‑Market (GTM) это традиционный подход вывода продукта на рынок. Маркетологи гонят рекламу, собирают лиды, ведут их по воронке (от узнавания — к интересу — к триалу — к покупке). Цель GTM — захватить максимальную ценность (value capture) из аудитории: сконвертировать как можно больше людей в клиентов и продажи. Вы наверняка такое видели.Go‑to‑Community (GTC) — альтернативный (и дополняющий) путь. Проще говоря, вместо того чтобы на каждом шаге пытаться выудить из аудитории пользу для себя, мы сначала создаем ценность вместе с сообществом и для сообщества. Мы привлекаем вокруг продукта широкое техническое коммьюнити, даже тех, кто прямо сейчас ничего не купит и не принесёт денег. Пусть люди учатся, обмениваются знаниями, придумывают интеграции, помогают друг другу, а там, глядишь, со временем часть из них созреет и до продаж. Да и не только продажи важны, лояльное сообщество будет поддерживать продукт, создавать контент, рекомендовать его коллегам. Маркетинг ловит лишь тех, кто готов купить, а комьюнити охватывает всех, кому интересна тема продукта, и вовлекает их на своих условиях.GTC не противоречит GTM, а дополняет его. Никто не отменяет воронку продаж, просто параллельно выстраивается воронка сообщества, и они должны работать синхронно. Идеальный сценарий: обе стратегии согласованы, и участники сообщества постепенно переходят в разряд лидов, когда придёт время. Пока же они остаются в комьюнити, получают там пользу и сами вносят вклад. Если же стратегии разрознены, то конечно будет перекос. Либо вы бескорыстно вкладываетесь в комьюнити без всякой выгоды для компании (отличная благотворительность, но бизнес это долго не выдержит), либо зациклены на продажах и игнорируете остальных фанатов продукта (упускаете кучу возможностей и сами того не зная отталкиваете людей). Нужно равновесие.При согласованной стратегии Go‑to‑Community подпитывает Go‑to‑Market воронку. Разрозненные стратегии ведут к перекосу, либо ценность создаётся только для сообщества, либо упор только на продажи без вовлечения комьюнити.Ставку на сообщество делают многие успешные технологические компании. В 2021-м сразу несколько «единорогов» с сообществом в ДНК вышли на IPO, вспомним хотя бы GitLab, HashiCorp, Duolingo. Они смогли превратить комьюнити вокруг своих продуктов в реальный драйвер роста и выручки. Например, у HashiCorp открытое сообщество не было чем‑то второстепенным, оно с первых дней определяло архитектуру продуктов, монетизацию и всю стратегию компании.Выходит, Go‑to‑Community не благотворительность, а инвестиция. Маркетинг приносит рост до определённого предела, дальше без сообщества не выехать. Разработчики больше доверяют друг другу, чем рекламе, любят сами пробовать и учиться. Поэтому стоит задача создать среду, где люди получают ценность: знания, поддержку, возможность влиять на продукт. Тогда сообщество само станет вашим маркетингом. Удовлетворённые участники начнут советовать решение коллегам, писать статьи и туториалы, расширять продукт под свои нужды, словом, делать ту работу, за которую маркетинг платит бюджетами.Роли в сообществе и их цепочки ценностиДопустим вы решились сместить фокус с агрессивного маркетинга на комьюнити. Возникает вопрос: «А что вообще из себя представляет мое сообщество? Кто эти люди и как с ними работать?» Ошибка в том, чтобы считать комьюнити однородной массой. На самом деле внутри есть несколько ролей. Люди по‑разному взаимодействуют с вашим продуктом и вносят разный вклад. В этой статье выделим три роли: мейнтейнеры, интеграторы и эдьютейтеры (расскажу, что имеется в виду). Для каждой опишем её мотивацию и цепочку ценности, то есть, какую ценность эта роль приносит проекту и что сама получает взамен. Мейнтейнеры (Maintainers) – хранители кодаЕсли ваш продукт связан с open‑source или имеет бесплатное ядро, наверняка есть люди, отвечающие за поддержание и развитие этого проекта, помимо вашей команды. Это и есть мейнтейнеры: разработчики, которые на постоянной основе вкладываются в код, ревьюят чужие контрибьюты, следят за качеством. Чаще всего это либо сотрудники компании, либо ключевые внешние энтузиасты, заслужившие доверие. Их главная цель сделать проект лучше для всех пользователей. Мотивация обычно техническая и идеологическая: мейнтейнеры хотят, чтобы продукт решал их (и не только их) задачи эффективно, был надежным, соответствовал видению. Часто они сами начинали этот проект или присоединились, потому что горят этой технологией.Ценность для компании: мейнтейнеры фактически ваши добровольные разработчики и архитекторы. Они фиксят баги, пилят фичи, держат все в порядке. По сути, без них проект бы загнулся от перегрузки. Хороший мейнтейнер экономит компании кучу ресурсов, обеспечивая качество продукта и доверие сообщества. Кроме того, мейнтейнеры мост между компанией и широким кругом контрибьюторов, они направляют новых участников, формируют культуру проекта. В идеале мейнтейнер из комьюнити становится настоящим лидером мнений по вашему продукту. Его одобрение или критика очень влияют на репутацию проекта среди разработчиков.Ценность для мейнтейнера: а что ему с этого? Разные люди находят разную выгоду. Кто‑то просто решает свои задачи. Кто‑то прокачивает навыки, строит карьеру в опенсорсе, статус мейнтейнера известного проекта дорогого стоит на рынке труда. Кто‑то получает моральное удовлетворение и уважение коллег. Иногда бывают и прямые выгоды: компания может спонсировать ключевых мейнтейнеров, донатить им, приглашать на конференции. HashiCorp, например, на заре развития своих OSS‑продуктов активно нанимала внешних контрибьюторов на работу и спонсировала их проекты. В итоге многие мейнтейнеры стали сотрудниками HashiCorp, классический win‑win, когда энтузиаст получает стабильную работу над любимым детищем, а компания лояльного эксперта.Как работать с мейнтейнерами: прежде всего, уважать и признавать их вклад. Ваша комьюнити‑стратегия должна явно давать мейнтейнерам место и голос. Простые шаги: регулярно благодарить публично, давать статус (например, звание Core Contributor, доступ в приватный Slack с командой). Прислушиваться, звать в совет проекта, собирать фидбэк перед релизами. Предоставить ресурсы: может быть, вы поможете им с инфраструктурой для тестирования, оплатите облако, пришлёте мерч. Сюда же со‑creation активности: проводите кодовые спринты вместе с мейнтейнерами, брейнштормьте фичи. Если есть возможность, выделите бюджет на гранты или part‑time контракты для особо ценных мейнтейнеров. Словом, встроите их в свою ценностную цепочку: мейнтейнеры дают проекту свой труд, а компания возвращает им поддержку и возможности. Тогда они будут еще больше заинтересованы развивать продукт, и вокруг них подтянутся другие контрибьюторы.Интеграторы (Integrators) – двигатели экосистемыПод интеграторами я понимаю всех, кто внедряет ваш продукт в реальных решениях и интегрирует его с другими системами. Это могут быть разработчики в сторонних компания, которые внедряют вашу библиотеку/платформу у себя в продакшене. Либо авторы плагинов, расширений, SDK для вашего продукта. Либо партнеры — консалтеры, системные интеграторы, делающие комплексные проекты на базе вашего решения. По сути, это продвинутые пользователи, которые не просто «пощупали» продукт, а глубоко его используют и зачастую расширяют функциональность под свои нужды.Ценность для компании: интеграторы — те самые люди, которые находят новым технологиям реальные применения. Они показывают, как продукт вписывается в разные use‑case, часто в связке с другим софтом. Например, кто‑то сделал открытый коннектор, чтобы ваша платформа работала с Kafka, и вот у вас целый новый сценарий использования для целой группы потенциальных клиентов. Интеграторы фактически расширяют рынок вашего продукта, создают вокруг него экосистему. Многие SaaS и платформы выстрелили именно благодаря сообществу, написавшему кучу плагинов и интеграций (взять ту же VS Code, тысячи расширений написаны внешними девелоперами). Кроме того, интеграторы часто становятся адвокатами продукта: раз они встроили его в своё решение, то будут убеждать и других в его ценности. Они же первыми ловят узкие места API, дают глубочайший фидбэк, могут помочь ответами на форумах. Ценность для интегратора: эти ребята обычно решают прикладные задачи. Их главный профит — рабочее решение проблемы. Если ваш продукт помог закрыть потребность — интегратор уже выиграл. Но сверх того: интегратор вкладывает время, чтобы проектировать архитектуру, писать код интеграции, и ему важно, чтобы усилия были оценены. Например, если он сделал плагин, видеть, что сообщество им пользуется, получить звезд на GitHub, благодарности, может даже клиентов. Многие интеграторы по совместительству партнеры в бизнес‑смысле. Компания‑разработчик может направлять клиентов к сертифицированным интеграторам для внедрения. Тогда интегратор зарабатывает как эксперт. Либо вы откроете свой Marketplace расширений и разрешите авторам монетизировать плагины. Либо хотя бы упомянете их кейс в блогах/на конференциях, что приносит признание. Короче, интегратору важно, чтобы его работа была востребована и приносила ему выгоду, будь то деньги, репутация или новые возможности.Как работать с интеграторами: в первую очередь, облегчить им жизнь технически. Документация, стабильные API, SDK — это база. Сделайте отличные примеры интеграции, опишите case studies, чтобы новым людям было проще повторить успех. Создайте каналы связи: технические каналы поддержки специально для интеграторов (Slack/форум с инженерами). Хороший ход запустить программу партнеров/интеграторов. Например, HashiCorp помимо сообщества юзеров имеет сеть системных интеграторов и облачных провайдеров, которые обучают и поддерживают новых клиентов. Их вовлекают: дают материалы, возможно, сертификации. Да, кстати, сертификация важный мотиватор. Если интегратор может получить статус «Certified Expert по продукту X», он с большим энтузиазмом погрузится (HashiCorp выдала уже 20k сертификатов через свою обучающую платформу). Не забудьте про витрину успехов: рассказывайте о решениях, которые делают интеграторы. Например, раздел на сайте «Built with OurProduct», чтобы все видели, какие крутые штуки делают люди. И, конечно, обратная связь: регулярно спрашивайте интеграторов, что улучшить. Может, проведите совместный co‑creation спринт: соберите самых активных внедренцев и ваших инженеров, и за пару дней допилите вместе интеграцию с популярным инструментом — они принесут экспертизу домена, вы — ресурсы разработки. Эдьютейтеры (Edutainers) – евангелисты и учителяТретья важнейшая группа — люди, которые обучают и вдохновляют остальных пользователей. Назовем их условно эдьютейтеры (от education + entertainer): авторы статей, туториалов, докладчики на митапах, ютуберы, создатели курсов. Про них часто говорят «Developer Advocates», «Evangelists», но мы сейчас имеем в виду внешних энтузиастов, не штатных деврелов компании. В каждом активном сообществе находятся личности, которые обожают рассказывать другим, как пользоваться технологией, делиться своим опытом, упрощать сложное.Ценность для компании: эти люди — настоящие мультипликаторы знаний. Благодаря им даже небольшой проект может получать непропорционально широкое внимание. Написал кто‑то толковый гайд на медиуме и сотни новых разработчиков узнали о вашем инструменте. Записал обзор на YouTube, тысячи посмотрели и заинтересовались. Контент от сообщества бьет все рекорды доверия: он независимый, «от такого же разработчика, как я». А если у вас ещё и своя площадка для контента… DigitalOcean выезжает на том, что тысячи авторов публикуют обучающие статьи на их платформе, кучу туториалов создали эту экосистему знаний вокруг продукта. Это работает лучше любой рекламы и SEO: люди приходят за решением проблемы и попутно узнают о вашем бренде. Помимо привлечения новых пользователей, эдьютейтеры очень помогают с onboarding, ускоряют активацию новичков. Хороший видеоурок или примеры от опытного пользователя сокращают время, за которое начинающий разработчик получит первый результат. А чем быстрее он увидит пользу, тем больше шанс, что останется с продуктом. В итоге эдьютейтеры снижают нагрузку на вашу команду и масштабируют охват аудитории.Ценность для эдьютейтера: многие делают это из страсти, нравится им делиться. Но обычно есть и расчёт: создание контента добавляет личного бренда. Стать известным спикером, набрать подписчиков, получить статус эксперта — всё это ценно для карьеры. Плюс банальное человеческое спасибо: когда твоя статья собирает апвоуты и благодарности, это мотивирует. Некоторые получают и материальное вознаграждение. Кто‑то монетизирует YouTube‑канал или платные курсы. В любом случае, эдьютейтеры ищут аудиторию и признание. И им гораздо приятнее сотрудничать с компанией, которая их ценит, чем делать все втуне.Как работать с эдьютейтерами: находить и вдохновлять их. Выявляйте активных авторов в сообществе: кто пишет блоги, отвечает на Stack Overflow, делает демо‑проекты. Начните с простого: репостните их статью в своих соцсетях, похвалите в рассылке. Дайте почувствовать, что компания видит их вклад. Далее можно формализовать. Многие запускают программы амбассадоров. Например, HashiCorp запустила HashiCorp Ambassador Program, сейчас там 100+ человек со всего мира. Отбор по критерию: делится знаниями, помогает другим, проявляет экспертизу. Амбассадоры получают официальный статус, мерч, а главное эксклюзивную инфу: брифинги о новых релизах, превью фич, закрытые сессии с командой. Это отличный стимул для эдьютейтеров, они чувствуют себя инсайдерами, первыми узнают новости и могут готовить контент заранее. Плюс им просто приятно быть в клубе причастных. Ваша задача — сделать так, чтобы создавать контент по вашему продукту было легко и выгодно. Предоставьте материалы: готовые презентации, демо‑проекты, библиотеку изображений. Запустите конкурс статей или хакатон по созданию туториалов, с призами и публикацией лучших работ. Организуйте мероприятия, где эдьютейтеры смогут выступить: митапы, вебинары. Поощряйте их рост: может, кто‑то из них созреет стать официальным Developer Advocate в вашей команде — прекрасный вариант рекрутинга из сообщества.Подытожим сегментацию: в сообществе есть разные роли, и у каждой своя цепочка ценности. Мейнтейнеры улучшают продукт и получают поддержку и признание. Интеграторы расширяют сферу применения продукта и получают решения для своих задач (плюс статус экспертов и, возможно, бизнес‑возможности). Эдьютейтеры распространяют знания и получают аудиторию и благодарность. Эти цепочки переплетены: обучающие статьи привлекают новых интеграторов, хорошие интеграции разгружают мейнтейнеров от просьб о фичах, мейнтейнеры дают материал для новых статей и так далее Наша задача как DevRel‑стратегов — поддерживать баланс, чтобы каждый тип участников чувствовал: вклад окупается, ему есть смысл дальше участвовать. Для этого пригодятся специальные методики, о которых далее.Методы DevRel 2.0: value chain mapping, persona-jobs, co-creationКогда мы поняли, кто наше сообщество и что ценно для разных людей, стоит применить несколько инструментов. Расскажу о трех: community value chain mapping, persona‑jobs и co‑creation спринты. Community Value Chain Mapping – карта ценности сообществаЗвучит мудрено, но идея простая: картирование цепочки ценности означает явным образом расписать, как каждая роль в сообществе создает ценность и получает её обратно. Фактически, мы частично это сделали выше в описании ролей. Зачем нужна такая карта? Чтобы убедиться, что нигде не образуется разрыв. Если обнаружим, что какая‑то группа дает ценности больше, чем получает (или наоборот — много получает, но мало отдает), можно внести коррективы в программу работы с комьюнити.Как это сделать на практике: возьмите роли (персоны) — мейнтейнер, интегратор, эдьютейтер. Для каждой нарисуйте две колонки: «Что он дает проекту» и «Что проект (компания) дает ему». Подробно перечислите пункты. Например:Мейнтейнер дает: время на разработку, ревью кода, отвечает на issues, направляет архитектуру. Получает: влияние на развитие продукта, благодарность сообщества, поддержку ресурсами (в идеале финансами), повышение статуса.Интегратор дает: новые кейсы использования, обратную связь, готовые интеграции/плагины для других пользователей, экспертные ответы новичкам. Получает: решение своих бизнес‑задач, улучшение продукта под свои нужды, признание как эксперта, возможно клиентов/доход через партнерство.Эдьютейтер дает: контент (статьи, доклады, примеры кода), обучает новых юзеров, увеличивает охват аудитории, снижает нагрузку на техподдержку. Получает: популярность в сообществе, прямую благодарность от аудитории, эксклюзивный доступ к информации, мерч/призы, карьерные возможности.Если выяснится, что интеграторы у нас очень ценны, а мы им почти ничего не предлагаем, надо думать, как увеличить для них отдачу. Или наоборот, мы всем дарим мерч и даём статус амбассадора, а толку от человека ноль, надо условия изменить, требовать минимальный вклад. Эта же карта ценности помогает обосновать руководству бюджет на комьюнити‑программы: вы показываете, какую работу выполняет каждая группа пользователей, и что нужно вложить, чтобы это продолжалось. По сути, value chain mapping переводит мягкое «строим отношения» в понятный бизнес‑язык «мы инвестируем X и получаем Y ценности». В open‑source мире такой подход уже применяется для оценки устойчивости проектов, упоминается создание «симбиотической цепочки ценности», где участники взаимно выгодно связаны.Рекомендую пересматривать карту ценности хотя бы раз в год. По мере роста сообщества могут появляться новые роли (например, отдельным сегментом выделятся дизайнеры или студенты), добавляйте их в карту. Так вы не упустите новую аудиторию. Кроме того, на основе этой карты удобно строить метрики: если знаете, что ценность дает, скажем, количество написанных комьюнити‑статей, можете отслеживать этот показатель и целенаправленно его растить инициативами.Persona-Jobs – объединяем портреты и задачиТеперь о методе persona‑jobs. Он объединяет классический подход персонажей (persona) с фреймворком Jobs‑to‑be‑Done (JTBD, «работы, которые хотят выполнить пользователи»). Идея пришла из продуктового маркетинга: чтобы лучше понять потребности, полезно описать не только «кто наш пользователь», но и «какую работу он нанимает наш продукт выполнить». В контексте DevRel и сообществ это означает: для каждой ключевой персоны из нашего комьюнити мы прописываем её конкретные задачи/цели, с которыми она к нам приходит, и проблемы, мешающие их достичь.Мы берем нашу персону — например, «Интегратор Игорь» (можно даже придать образ: архитектор 35 лет, в большой компании, отвечает за внедрение технологий). Выписываем, какие у него Jobs‑to‑be‑Done относительно нашего продукта. Допустим интегрировать библиотеку в существующую систему без простоев; убедиться в безопасности решения для продакшена; обучить команду пользоваться новым инструментом; и тому подобное Для каждой такой задачи укажем, что ему помогает или мешает. Возможно, у Игоря боль в нехватке документации по масштабированию, или бюрократия на согласование новых технологий. Проделав это, мы увидим, как лучше помочь интеграторам: например, сделать whitepaper «Как убедить менеджмент внедрить OurProduct» или добавить раздел доки про безопасность. Точно так же делаем для мейнтейнера Марины (job: привлечь новых контрибьюторов, автоматизировать релизы, и так далее) и эдьютейтера Евгения (job: быстро разбираться в новых фичах, получать благодарную аудиторию, иметь доступ к примерам из реальной практики, и так далее).Персона сама по себе фокусируется на кто наш пользователь, каков его контекст и мотивы. А Jobs‑to‑be‑Done фокусируется на что пользователь пытается сделать и почему. Вместе они позволяют выйти за рамки стереотипов. Например, если смотреть только на персону «DevOps инженер, 5 лет опыта, такого‑то возраста», мы можем упустить, что конкретно ему нужно от нашего сообщества. А если смотреть только на абстрактный «job: получить ответ на вопрос по настройке CI/CD», упустим контекст, новичок это или эксперт, как он предпочитает учиться (читать, смотреть видео, задавать в чате?). Persona‑JTBD гибрид учитывает и то, и другое.В итоге получаем очень интересные инсайты. Например, выясняется, что молодые разработчики (персона: Студент Саша) хотят прокачать навыки (job: найти pet‑проект и ментора). Тогда вам стоит запустить для них программу стажировок в опенсорс‑проекте сообщества или выделить «good first issues». А, скажем, Solution‑архитекторы в компаниях (персона: Архитектор Антон) хотят делиться экспертизой (job: выступать на конференциях, чтобы признали). Значит, их можно вовлекать модераторами вебинаров, авторами гостевых постов, то есть давать площадку для самореализации в рамках вашего комьюнити. Применять persona‑jobs можно на этапе планирования DevRel‑инициатив. Собираетесь сделать хакатон, подумайте, для каких персон и каких «jobs» он вообще нужен. Закрывает ли он задачу мейнтейнера (например, собрать новых контрибьюторов)? Или нацелен на эдьютейтеров (дать им показать свой проект)? Если не понимаете, для кого стараетесь, возможно, мероприятие получится пустым. А когда явно видишь: для такой‑то персоны решаем такую‑то задачу, успех измеряется легко. Co-creation спринты – совместное творчество с комьюнитиПоследний метод — co‑creation спринты, то бишь совместные короткие циклы разработки/творчества с участием сообщества. Идея навеяна дизайн‑спринтами и хакатонами, но с упором на совместную работу команды продукта и внешних участников. Если перевести дословно — спринты с со‑творчеством. Это могут быть разные форматы:Community Hackathon, классика: вы объявляете тему (например, расширения для вашего API), собираете команды из внешних разработчиков и своих менторов, и за выходные они пилят готовые проекты. В отличие от обычного хакатона, здесь важно участие ваших инженеров бок о бок с комьюнити — это ломает барьеры «разработчик vs компания». Все становятся коллегами на пару дней.Documentation Sprint, узконаправленный спринт, когда собираются техписатели, эдьютейтеры, разработчики и дружно улучшают документацию или обучающие материалы. Feedback/Design Sprint — это когда сообщество участвует в проектировании новых фич. Например, у вас назрел большой релиз, проведите двухдневный спринт с наиболее вовлеченными пользователями и мейнтейнерами. В первый день соберите боль и хотелки (что нужно улучшить, какие use‑case не покрыты), во второй совместно приоритизируйте и набросайте макеты решений. Можно даже прототипировать вместе. Content Sprint, похож на докатон, но шире по форматам. Например, объявляете «Writing Sprint» на неделю: каждый день даёте тему (пн — установка продукта, вт — кейсы интеграции, ср — разбор ошибок и тому подобное), участники пишут небольшие заметки или снимают скринкасты. В конце недели готов целый пакет контента от сообщества для сообщества.Ключевое в co‑creation спринтах это не соревнование (как часто бывает в хакатонах), а именно сотрудничество. Здесь уместно убрать соревновательность и делать упор на общий результат. Как в Open Source, все коммитят в один проект. Роли можно распределять: кто‑то кодит, кто‑то тестирует, кто‑то пишет документацию. Это очень сплочает. Люди чувствуют: «Мы вместе сделали что‑то крутое, и наш вклад встроен прямо в продукт/доку/базу знаний».Эффект от таких спринтов потрясающий. Во‑первых, куча полезных артефактов, новые фичи, улучшенные доки, примеры, плагины. Во‑вторых, вы выращиваете новых лидеров: тот, кто блеснул на спринте идеей или решением, потом наверняка станет еще активнее в сообществе. В‑третьих, это привлекает внимание более широкой аудитории, результаты спринта можно анонсить, хвастаться, мол вот, сообщество вместе с нами сделало релиз. Для участников co‑creation это тоже реклама и признание.Планируя co‑creation sprint, четко обозначьте цель и формат. Люди должны понимать, что на выходе. Желательно ограничить время (не более недели, а лучше 1–3 дня). И обязательно отпразднуйте результаты, финальный демо‑день, список всех авторов, сертификаты участникам, сувениры, словом, отметьте вклад каждого. Тогда в следующий раз желающих будет ещё больше.Конечно, полностью заменить классический маркетинг на одну только работу с сообществом не получится. Да и не нужно. Правильный шаг — интегрировать GTC и GTM. Например, KPI маркетинга и DevRel должны быть взаимосвязаны. Сообща решайте, как перевести рост активности в сообществе в бизнес‑метрики: «community members → leads → клиенты». Куда приятнее иметь дело с технологией, вокруг которой есть дружное сообщество, где твой вклад ценят, где можно учиться и расти вместе. Такие продукты мы выбираем сердцем, и остаёмся с ними надолго. Так что стройте сообщества, а не только воронки продаж. Если у вас есть опыт внедрения подобных стратегий, расскажите в комментариях.Чтобы превратить GTC из концепции в работающий процесс, присмотритесь к курсу OTUS «DevRel». В программе — EVP/EJM, стратегия HR-бренда, метрики комьюнити и отчётность, контент- и event-практики, работа с амбассадорами и внешними сообществами на реальных кейсах. Если хотите понять формат обучения — записывайтесь на бесплатные демо-уроки от преподавателей курса:20 ноября: «DevRel и HR на практике: формула успешных мероприятий для разработчиков». Записаться25 ноября: «DevRel и HR-метрики: какие показатели будут важны стейкхолдерам в 2026 году». ЗаписатьсяТеги:devrelgtm.gtcGo-to-CommunityGo-to-Marketсообщество разработчиковворонка сообществаметрики комьюнитиHR-брендХабы:Блог компании OTUSDeveloper RelationsУправление продуктом",181,0,0,17 мин,https://habr.com/ru/companies/otus/articles/961436/,26000,3438,3
