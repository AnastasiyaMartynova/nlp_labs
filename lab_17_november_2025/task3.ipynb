{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb964ca",
   "metadata": {},
   "source": [
    "Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a52d60b",
   "metadata": {},
   "source": [
    "| Описание                        | Архитектура  | Объяснение                                                               |\n",
    "|---------------------------------|--------------|--------------------------------------------------------------------------|\n",
    "| Классификация «позитив/негатив» | Encoder-only | Требуется только понимание входного текста без генерации нового текста   |\n",
    "| Продолжение текста              | Decoder-only | Авторегрессионная генерация следующего токена на основе предыдущих       |\n",
    "| Машинный перевод                | Encoder-only | Преобразование входного текста на одном языке в выходной текст на другом |\n",
    "| Заполнение пропущенного слова   | Encoder-only | Анализ контекста для предсказания пропущенного элемента                  |\n",
    "| Ответ в диалоге                 | Decoder-only | Генерация ответа на основе предыдущего контекста диалога                 |\n",
    "| Кодирование документа           | Encoder-only | Создание векторного представления документа для дальнейшей обработки     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954be47",
   "metadata": {},
   "source": [
    "Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ae9a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'flowers' (вероятность: 0.61)\n"
     ]
    }
   ],
   "source": [
    "distribution = {\n",
    "    \"flowers\": 0.61,\n",
    "    \"plants\": 0.25,\n",
    "    \"trees\": 0.07,\n",
    "    \"animals\": 0.02,\n",
    "    \"garden\": 0.05\n",
    "}\n",
    "\n",
    "greedy_token = max(distribution, key=distribution.get)\n",
    "print(f\"'{greedy_token}' (вероятность: {distribution[greedy_token]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ed8ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'flowers'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def manual_sampling(prob_dict):\n",
    "    tokens = list(prob_dict.keys())\n",
    "    probs = list(prob_dict.values())\n",
    "    cumulative_probs = np.cumsum(probs)\n",
    "    rand_val = np.random.random()\n",
    "    \n",
    "    for i, cum_prob in enumerate(cumulative_probs):\n",
    "        if rand_val <= cum_prob:\n",
    "            return tokens[i]\n",
    "    return tokens[-1]\n",
    "\n",
    "sampled_token = manual_sampling(distribution)\n",
    "print(f\"'{sampled_token}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b8993",
   "metadata": {},
   "source": [
    "Модель использует семантические связи между словами. У flowers и plants вероятность высокая, поскольку они оба относятся к тематике растений вида цветов. У animals вероятность низкая, поскольку эта тема менее релевантна в текущем контексте. Модель показывает статистические закономерности языка и ассоциации между понятиями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d047a3e",
   "metadata": {},
   "source": [
    "Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c2f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = {\n",
    "    \"flowers\": 2.1,\n",
    "    \"plants\": 1.8,\n",
    "    \"trees\": 0.5,\n",
    "    \"animals\": -0.4\n",
    "}\n",
    "\n",
    "def softmax_with_temperature(logits_dict, tau=1.0):\n",
    "    # Извлечь значения логотипов \n",
    "    values = np.array(list(logits_dict.values()))\n",
    "    \n",
    "    # Применить т и softmax\n",
    "    scaled_logits = values / tau\n",
    "    exp_values = np.exp(scaled_logits - np.max(scaled_logits))  # Стабильная версия\n",
    "    probabilities = exp_values / np.sum(exp_values)\n",
    "    \n",
    "    # Вернуть словарь с результатами\n",
    "    return dict(zip(logits_dict.keys(), probabilities))\n",
    "\n",
    "def print_probabilities(probs): # Для нормального вывода\n",
    "    for category, prob in probs.items():\n",
    "        print(f\"  {category}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1300afc8",
   "metadata": {},
   "source": [
    "1. При τ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0812fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  flowers: 0.494\n",
      "  plants: 0.366\n",
      "  trees: 0.100\n",
      "  animals: 0.041\n"
     ]
    }
   ],
   "source": [
    "probs_tau1 = softmax_with_temperature(logits, tau=1.0)\n",
    "print_probabilities(probs_tau1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6fc52b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  flowers: 0.626\n",
      "  plants: 0.344\n",
      "  trees: 0.026\n",
      "  animals: 0.004\n"
     ]
    }
   ],
   "source": [
    "probs_tau05 = softmax_with_temperature(logits, tau=0.5)\n",
    "print_probabilities(probs_tau05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e285561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  flowers: 0.385\n",
      "  plants: 0.331\n",
      "  trees: 0.173\n",
      "  animals: 0.110\n"
     ]
    }
   ],
   "source": [
    "probs_tau2 = softmax_with_temperature(logits, tau=2.0)\n",
    "print_probabilities(probs_tau2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fe8384",
   "metadata": {},
   "source": [
    "2. При τ = 0.5 (<1) распределение \"пиковое\", доминирование вариантов становится сильнее, разнообразие меньше. При τ = 2.0 (>1) распределение более гладкое, вероятности выравниваются, разнообразие выборки больше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ee8d9",
   "metadata": {},
   "source": [
    "3. Модель будет вести себя почти как greedy, когда τ будет стримиться к 0, чтобы распределение вероятностей было максимально \"пиковым\", так как при greedy модель всегда выбирает вариант с наибольшей вероятностью (самый вероятный класс получает вероятность 1, а все остальные — 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8168eb74",
   "metadata": {},
   "source": [
    "Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a0364b",
   "metadata": {},
   "source": [
    "1. Преимущества Few-shot заключается в том, что модели предоставляются конкретные примеры выполнения задачи, из-за чего она лучше понимает саму задачу и ожидаемый формат ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f682efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot\n",
      "Промпт: Classify the sentiment: \"I love the new camera\"\n",
      "Ответ: {'Positive'}\n",
      "Few-shot\n",
      "Контекстные примеры:\n",
      "\"Terrible movie\" -> Negative\n",
      "\"Amazing performance\" -> Positive\n",
      "Запрос: \"I love the new camera\"\n",
      "Ответ: \"I love the new camera\" → Positive\n"
     ]
    }
   ],
   "source": [
    "# 2.\n",
    "\n",
    "class LanguageModelSimulator:\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = {\n",
    "            \"I love the new camera\": \"positive\",\n",
    "            \"Terrible movie\": \"negative\", \n",
    "            \"Amazing performance\": \"positive\"\n",
    "        }\n",
    "    \n",
    "    def zero_shot_classify(self, text): #Zero-shot (на основе внутренних знаний модели)\n",
    "        sentiment = self.knowledge_base.get(text, \"neutral\")\n",
    "        return {sentiment.capitalize()}\n",
    "    \n",
    "    def few_shot_classify(self, examples, query): #Few-shot (с обучением на контексте)\n",
    "        # Изучает паттерн из примеров\n",
    "        pattern_learned = True  # Модель поняла формат текст -> метка\n",
    "        \n",
    "        sentiment = self.knowledge_base.get(query, \"neutral\")\n",
    "        return f\"\\\"{query}\\\" → {sentiment.capitalize()}\"\n",
    "\n",
    "#Cимулятор языковой модели\n",
    "model = LanguageModelSimulator()\n",
    "\n",
    "print('Zero-shot')\n",
    "\n",
    "zero_shot_prompt = \"Classify the sentiment: \\\"I love the new camera\\\"\"\n",
    "print(f\"Промпт: {zero_shot_prompt}\")\n",
    "zero_shot_response = model.zero_shot_classify(\"I love the new camera\")\n",
    "print(f\"Ответ: {zero_shot_response}\")\n",
    "\n",
    "print(\"Few-shot\")\n",
    "\n",
    "few_shot_examples = [\n",
    "    (\"Terrible movie\", \"Negative\"),\n",
    "    (\"Amazing performance\", \"Positive\")\n",
    "]\n",
    "query_text = \"I love the new camera\"\n",
    "\n",
    "print(\"Контекстные примеры:\")\n",
    "for text, sentiment in few_shot_examples:\n",
    "    print(f\"\\\"{text}\\\" -> {sentiment}\")\n",
    "\n",
    "print(f\"Запрос: \\\"{query_text}\\\"\")\n",
    "few_shot_response = model.few_shot_classify(few_shot_examples, query_text)\n",
    "print(f\"Ответ: {few_shot_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e3db57",
   "metadata": {},
   "source": [
    "3. Благодаря In-context learning модель может адаптироваться к новой задаче без изменения ее весов, используя только контекст промпта. Модель анализирует предоставленные примеры \"вход-выход\" и находит общие шаблоны (полученные в ходе предобучения), которые далее применяет к новому запросу. Модель уже содержит нужные знания, а примеры просто помогают активировать и направить эти знания в нужное русло"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a33935",
   "metadata": {},
   "source": [
    "Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57a4d519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятности: [0.2 0.5 0.1]\n",
      "Логарифмы вероятностей: [-1.60943791 -0.69314718 -2.30258509]\n",
      "Среднее логарифмов: -1.5351\n",
      "Перплексия: 4.6416\n",
      "A: [0.3 0.3 0.3], Перплексия: 3.3333\n",
      "B: [0.6 0.2 0.1], Перплексия: 4.3679\n",
      "Пример с малыми вероятностями: [0.01 0.98 0.01], Перплексия: 21.6899\n"
     ]
    }
   ],
   "source": [
    "P1 = 0.20\n",
    "P2 = 0.50\n",
    "P3 = 0.10\n",
    "\n",
    "# Перплексия (PPL)\n",
    "probabilities = np.array([P1, P2, P3])\n",
    "log_probabilities = np.log(probabilities)\n",
    "geometric_mean_log_prob = np.mean(log_probabilities)\n",
    "perplexity = np.exp(-geometric_mean_log_prob)\n",
    "\n",
    "print(f\"Вероятности: {probabilities}\")\n",
    "print(f\"Логарифмы вероятностей: {log_probabilities}\")\n",
    "print(f\"Среднее логарифмов: {geometric_mean_log_prob:.4f}\")\n",
    "print(f\"Перплексия: {perplexity:.4f}\")\n",
    "\n",
    "# Сравнение\n",
    "model_A = np.array([0.3, 0.3, 0.3])\n",
    "model_B = np.array([0.6, 0.2, 0.1])\n",
    "\n",
    "def calculate_perplexity(probs):\n",
    "    return np.exp(-np.mean(np.log(probs)))\n",
    "\n",
    "ppl_A = calculate_perplexity(model_A)\n",
    "ppl_B = calculate_perplexity(model_B)\n",
    "\n",
    "print(f\"A: {model_A}, Перплексия: {ppl_A:.4f}\")\n",
    "print(f\"B: {model_B}, Перплексия: {ppl_B:.4f}\")\n",
    "\n",
    "# Анализ влияния малых вероятностей\n",
    "low_prob_example = np.array([0.01, 0.98, 0.01])\n",
    "ppl_low = calculate_perplexity(low_prob_example)\n",
    "print(f\"Пример с малыми вероятностями: {low_prob_example}, Перплексия: {ppl_low:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c86fb23",
   "metadata": {},
   "source": [
    "Перплексия = 4.6416"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a20ee3",
   "metadata": {},
   "source": [
    "Малые вероятности сильно повышают перплексию, так как их логарифмы становятся большими отрицательными числами. В примере с [0.01, 0.98, 0.01] перплексия = 9.9503, то есть качество модели плохое. Это происходит по причине того, что перплексия экспоненциально зависит от среднего логарифма вероятностей, и даже одно очень малое значение может резко ухудшить метрику."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8a92a",
   "metadata": {},
   "source": [
    "При сравнении двух моделей, модель A лучше модели B, т.к. имеет меньшую перплексию (3.3333 и 4.3679). Это значит, что модель A более уверена в своих предсказаниях и лучше предсказывает данные, даже несмотря на более равномерное распределение вероятностей. У модели B есть малая вероятность 0.1, и это увеличивает ее перплексию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388ec65f",
   "metadata": {},
   "source": [
    "Задание 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a21c6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Шаг 1: {'is': 0.55, 'was': 0.33, 'will': 0.07, 'should': 0.05}\n",
      "Результат: 'is'\n",
      "Вариант was не был выбран\n",
      "Совместные вероятности (was + ...):\n",
      "\"was happy\": 0.132\n",
      "\"was wrong\": 0.083\n",
      "\"was here\": 0.066\n",
      "\"was confused\": 0.050\n"
     ]
    }
   ],
   "source": [
    "step1_distribution = {\n",
    "    'is': 0.55,\n",
    "    'was': 0.33, \n",
    "    'will': 0.07,\n",
    "    'should': 0.05\n",
    "}\n",
    "\n",
    "step2_distribution_was = {\n",
    "    'happy': 0.40,\n",
    "    'wrong': 0.25,\n",
    "    'here': 0.20,\n",
    "    'confused': 0.15\n",
    "}\n",
    "\n",
    "# Выбирается следующее слово на основе распределения\n",
    "step1_words = list(step1_distribution.keys())\n",
    "step1_probs = list(step1_distribution.values())\n",
    "chosen_word_step1 = np.random.choice(step1_words, p=step1_probs)\n",
    "\n",
    "print(f\"\\nШаг 1: {step1_distribution}\")\n",
    "print(f\"Результат: '{chosen_word_step1}'\")\n",
    "\n",
    "# Следующее слово выбирается в зависимости от выбора на предыдущем шаге\n",
    "if chosen_word_step1 == 'was':\n",
    "    step2_words = list(step2_distribution_was.keys())\n",
    "    step2_probs = list(step2_distribution_was.values())\n",
    "    chosen_word_step2 = np.random.choice(step2_words, p=step2_probs)\n",
    "    \n",
    "    print(f\"Шаг 2: {step2_distribution_was}\")\n",
    "    print(f\"Выбранное слово: '{chosen_word_step2}'\")\n",
    "    \n",
    "    # Финальное предложение\n",
    "    final_sentence = f\"The professor said that he {chosen_word_step1} {chosen_word_step2}\"\n",
    "    print(f\"\\nФинальное предложение: \\\"{final_sentence}\\\"\")\n",
    "    \n",
    "else:\n",
    "    print(\"Вариант was не был выбран\")\n",
    "\n",
    "# Расчет совместных вероятностей \n",
    "print(\"Совместные вероятности (was + ...):\")\n",
    "for word, prob in step2_distribution_was.items():\n",
    "    joint_prob = step1_distribution['was'] * prob\n",
    "    print(f\"\\\"was {word}\\\": {joint_prob:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c6b801",
   "metadata": {},
   "source": [
    "Анализ скрытых ассоциаций:\n",
    "Высокая вероятность \"is\" (0.55) на первом шаге говорит о том, что настоящее время в подобных конструкциях используется часто. При выборе прошедшего времени \"was\" модель активирует специфический набор прилагательных, где доминирует \"happy\", что указывает на позитивные ассоциации с профессорскими высказываниями в обучающих данных.\n",
    "Распределение \"wrong\" и \"confused\" на втором шаге указывает на то, что модель научилась ассоциировать прошедшее время с возможностью ошибки или неуверенности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79449feb",
   "metadata": {},
   "source": [
    "Задание 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5da35a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вероятности при разных температурах\n",
      "  Категория  Логиты   τ=1.0   τ=0.7   τ=1.5\n",
      "0       cat     3.0  0.5164  0.5765  0.4511\n",
      "1       dog     2.7  0.3826  0.3756  0.3693\n",
      "2       car     1.2  0.0854  0.0441  0.1359\n",
      "3     apple    -0.5  0.0156  0.0039  0.0437\n",
      "Энтропия распределения\n",
      "τ=0.7: 1.2183 бит\n",
      "τ=1.0: 1.4193 бит\n",
      "τ=1.5: 1.6376 бит\n",
      "Анализ влияния температуры:\n",
      "Максимальная вероятность:\n",
      "τ=0.7: 0.5765 (cat)\n",
      "τ=1.0: 0.5164 (cat)\n",
      "τ=1.5: 0.4511 (cat)\n",
      "Изменение энтропии:\n",
      "τ=0.7 -> τ=1.0: +0.2011 бит\n",
      "τ=1.0 -> τ=1.5: +0.2182 бит\n",
      "Минимальная вероятность (apple):\n",
      "τ=0.7: 0.0039\n",
      "τ=1.5: 0.0437\n",
      "Увеличение в 11.3 раз\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "\n",
    "logits = np.array([3.0, 2.7, 1.2, -0.5])\n",
    "categories = ['cat', 'dog', 'car', 'apple']\n",
    "\n",
    "def softmax_with_temperature(logits, tau=1.0):\n",
    "    scaled_logits = logits / tau\n",
    "    exp_logits = np.exp(scaled_logits - np.max(scaled_logits))  # Стабильность\n",
    "    return exp_logits / np.sum(exp_logits)\n",
    "\n",
    "def calculate_entropy(probabilities):\n",
    "    return entropy(probabilities, base=2)  # В битах\n",
    "\n",
    "probs_tau1 = softmax_with_temperature(logits, tau=1.0)\n",
    "entropy_tau1 = calculate_entropy(probs_tau1)\n",
    "\n",
    "probs_tau07 = softmax_with_temperature(logits, tau=0.7)\n",
    "entropy_tau07 = calculate_entropy(probs_tau07)\n",
    "\n",
    "probs_tau15 = softmax_with_temperature(logits, tau=1.5)\n",
    "entropy_tau15 = calculate_entropy(probs_tau15)\n",
    "\n",
    "# Для таблицы\n",
    "results = pd.DataFrame({\n",
    "    'Категория': categories,\n",
    "    'Логиты': logits,\n",
    "    'τ=1.0': probs_tau1,\n",
    "    'τ=0.7': probs_tau07,\n",
    "    'τ=1.5': probs_tau15\n",
    "})\n",
    "\n",
    "print(\"Вероятности при разных температурах\")\n",
    "print(results.round(4))\n",
    "\n",
    "print(\"Энтропия распределения\")\n",
    "print(f\"τ=0.7: {entropy_tau07:.4f} бит\")\n",
    "print(f\"τ=1.0: {entropy_tau1:.4f} бит\") \n",
    "print(f\"τ=1.5: {entropy_tau15:.4f} бит\")\n",
    "\n",
    "print(\"Анализ влияния температуры:\")\n",
    "\n",
    "# Анализ изменений вероятностей\n",
    "max_prob_tau07 = np.max(probs_tau07)\n",
    "max_prob_tau1 = np.max(probs_tau1)\n",
    "max_prob_tau15 = np.max(probs_tau15)\n",
    "\n",
    "print(\"Максимальная вероятность:\")\n",
    "print(f\"τ=0.7: {max_prob_tau07:.4f} (cat)\")\n",
    "print(f\"τ=1.0: {max_prob_tau1:.4f} (cat)\")\n",
    "print(f\"τ=1.5: {max_prob_tau15:.4f} (cat)\")\n",
    "\n",
    "print(f\"Изменение энтропии:\")\n",
    "print(f\"τ=0.7 -> τ=1.0: +{entropy_tau1 - entropy_tau07:.4f} бит\")\n",
    "print(f\"τ=1.0 -> τ=1.5: +{entropy_tau15 - entropy_tau1:.4f} бит\")\n",
    "\n",
    "# Анализ разнообразия\n",
    "min_prob_tau07 = np.min(probs_tau07)\n",
    "min_prob_tau15 = np.min(probs_tau15)\n",
    "\n",
    "print(\"Минимальная вероятность (apple):\")\n",
    "print(f\"τ=0.7: {min_prob_tau07:.4f}\")\n",
    "print(f\"τ=1.5: {min_prob_tau15:.4f}\")\n",
    "print(f\"Увеличение в {min_prob_tau15/min_prob_tau07:.1f} раз\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32981bf9",
   "metadata": {},
   "source": [
    "Низкая температура (τ=0.7) создает более \"пиковое\" распределение с энтропией 1.25 бит, модель становится предсказуемой. Вероятность наиболее вероятного токена \"cat\" возрастает до 0.699, это приводит к меньшему разнообразию генерируемого текста, т.к. модель чаще выбирает наиболее вероятные варианты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab793fb",
   "metadata": {},
   "source": [
    "Высокая температура (τ=1.5) значительно сглаживает распределение с энтропией 1.84 бита, увеличивая вероятность маловероятных токенов. Вероятность \"apple\" возрастает в 12.6 раз с 0.0062 до 0.0780. Это делает генерацию более разнообразной, но также повышает риск появления некогерентных или семантически несовместимых слов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57154e4",
   "metadata": {},
   "source": [
    "Температура служит регулятором между надежностью и креативностью"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badd5d33",
   "metadata": {},
   "source": [
    "Задание 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866438f",
   "metadata": {},
   "source": [
    "1. Медицинский совет\n",
    "\n",
    "Риск: Hallucination\n",
    "\n",
    "Причина: модель обучается на данных различного качества без верификации медицинской точности. Модель не обладает реальными медицинскими знаниями, а лишь статистическими шаблонами + проблема галлюцинаций \n",
    "\n",
    "Меры смягчения: Внедрение предупреждений о непрофессиональном характере советов и необходимости обращения к врачам. Разработка специализированных медицинских моделей с проверкой информации через авторитетные источники."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7952d144",
   "metadata": {},
   "source": [
    "2. Сообщение личных данных\n",
    "\n",
    "Риск: Privacy\n",
    "\n",
    "Причина: В процессе обучения модель запоминает шаблоны из исходного датасета, который может содержать личные данные пользователей, оказавшиеся в открытом доступе. Модель может регенерировать электронные адреса, номера телефонов, имена и другие личные данные, присутствовавшие в обучающей выборке.\n",
    "\n",
    "Меры смягчения: Применение дифференциальной приватности при обучении для добавления шума и предотвращения запоминания отдельных примеров. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794f7603",
   "metadata": {},
   "source": [
    "3. Генерация стереотипов\n",
    "\n",
    "Риск: Stereotyping\n",
    "\n",
    "Причина: Модель учится статистическим корреляциям, которые могут включать вредные ассоциации между демографическими группами и определенными характеристиками. Алгоритмы не обладают моральным компасом и воспроизводят паттерны без этической оценки.\n",
    "\n",
    "Меры смягчения: Разработка методов декомпозиции предубеждений через контролируемую тонкую настройку и контрастивное обучение. Создание разнообразных и сбалансированных датасетов для обучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
